{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9OJMf9UmHkZ8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OJMf9UmHkZ8",
        "outputId": "dba5b8f4-6213-4f34-d210-9400b6288a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n",
            "Requirement already satisfied: scipy==1.11.1 in /usr/local/lib/python3.10/dist-packages (1.11.1)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy==1.11.1) (1.26.4)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.2)\n",
            "Requirement already satisfied: xlstm in /usr/local/lib/python3.10/dist-packages (1.0.8)\n",
            "Requirement already satisfied: dacite in /usr/local/lib/python3.10/dist-packages (1.8.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "!pip install mne\n",
        "!pip install scipy==1.11.1\n",
        "!pip install omegaconf\n",
        "!pip install xlstm\n",
        "!pip install dacite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "810dc419",
      "metadata": {
        "id": "810dc419"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import from_numpy as np2TT\n",
        "from torchinfo import summary\n",
        "\n",
        "from os.path import expanduser\n",
        "from scipy.io import savemat\n",
        "import numpy as np\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import mne\n",
        "import sys\n",
        "import os\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "from dacite import from_dict\n",
        "from dacite import Config as DaciteConfig\n",
        "from scipy.io import loadmat\n",
        "from scipy import signal\n",
        "from matplotlib.colors import rgb2hex\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from xlstm import (\n",
        "    xLSTMBlockStack,\n",
        "    xLSTMBlockStackConfig,\n",
        "    mLSTMBlockConfig,\n",
        "    mLSTMLayerConfig,\n",
        "    sLSTMBlockConfig,\n",
        "    sLSTMLayerConfig,\n",
        "    FeedForwardConfig,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5141b59c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5141b59c",
        "outputId": "e3cd93cc-e754-4af9-92c5-d29078b30fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: \" + str(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "15e9ee63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15e9ee63",
        "outputId": "cc860e7c-e1d0-406f-8bc9-e6846a439971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "use_google_drive = True\n",
        "if use_google_drive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proposed model\n"
      ],
      "metadata": {
        "id": "HJLfDGXuPA5e"
      },
      "id": "HJLfDGXuPA5e"
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMConvAutoencoder3(nn.Module):\n",
        "    def __init__(self, input_dim=18, num_layers = 1):\n",
        "        super(LSTMConvAutoencoder3, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(256, 256, num_layers, batch_first=True)\n",
        "\n",
        "        # Encoder: 3 1D convolutional layers\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(input_dim, 64, kernel_size=5, stride=2, padding=2),  # [batch_size, 64, 256]\n",
        "            #nn.ReLU(),\n",
        "            nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2),             # [batch_size, 128, 128]\n",
        "            #nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, kernel_size=5, stride=2, padding=2),            # [batch_size, 256, 64]\n",
        "            #nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder: 3 1D transposed convolutional layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose1d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1),  # [batch_size, 128, 128]\n",
        "            #nn.ReLU(),\n",
        "            nn.ConvTranspose1d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1),   # [batch_size, 64, 256]\n",
        "            #nn.ReLU(),\n",
        "            nn.ConvTranspose1d(64, input_dim, kernel_size=5, stride=2, padding=2, output_padding=1),  # [batch_size, input_channels, 512]\n",
        "            #nn.Sigmoid()  # Sigmoid for output normalization between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(1)\n",
        "\n",
        "        # Forward pass through encoder\n",
        "        x = self.encoder(x)                #encoder takes [batch_size, input_dim, sequence_length]\n",
        "        x, _ = self.lstm(x.permute(0,2,1))\n",
        "        # Forward pass through decoder\n",
        "        x = self.decoder(x.permute(0,2,1))\n",
        "\n",
        "        return x.unsqueeze(1)"
      ],
      "metadata": {
        "id": "DLxMj8yKO_pi"
      },
      "id": "DLxMj8yKO_pi",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e03ceb85",
      "metadata": {
        "id": "e03ceb85"
      },
      "source": [
        "# CLEEGN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "30031a81",
      "metadata": {
        "id": "30031a81"
      },
      "outputs": [],
      "source": [
        "class Permute2d(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(Permute2d, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.permute(x, self.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0fe70d25",
      "metadata": {
        "id": "0fe70d25"
      },
      "outputs": [],
      "source": [
        "class CLEEGN(nn.Module):\n",
        "    def __init__(self, n_chan, fs, N_F=20, tem_kernelLen=0.1):\n",
        "        super(CLEEGN,self).__init__()\n",
        "        self.n_chan = n_chan\n",
        "        self.N_F = N_F\n",
        "        self.fs = fs\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, n_chan, (n_chan, 1), padding=\"valid\", bias=True),\n",
        "            Permute2d((0, 2, 1, 3)),\n",
        "            nn.BatchNorm2d(1, eps=1e-3, momentum=0.99)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(1, N_F, (1, int(fs * tem_kernelLen)), padding=\"same\", bias=True),\n",
        "            nn.BatchNorm2d(N_F, eps=1e-3, momentum=0.99)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(N_F, N_F, (1, int(fs * tem_kernelLen)), padding=\"same\", bias=True),\n",
        "            nn.BatchNorm2d(N_F, eps=1e-3, momentum=0.99)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(N_F, n_chan, (n_chan, 1), padding=\"same\", bias=True),\n",
        "            nn.BatchNorm2d(n_chan, eps=1e-3, momentum=0.99)\n",
        "        )\n",
        "        self.conv5 = nn.Conv2d(n_chan, 1, (n_chan,1), padding=\"same\", bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        # decoder\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1D-ResCNN\n"
      ],
      "metadata": {
        "id": "TuGCRRZuEuAs"
      },
      "id": "TuGCRRZuEuAs"
    },
    {
      "cell_type": "code",
      "source": [
        "class Res_BasicBlock(nn.Module):\n",
        "    def __init__(self, kernelsize, stride=1):\n",
        "        super(Res_BasicBlock, self).__init__()\n",
        "        self.bblock = nn.Sequential(\n",
        "            nn.Conv1d(32, 32, kernel_size=kernelsize, stride=stride, padding='same'),\n",
        "            nn.BatchNorm1d(32),\n",
        "            #nn.ReLU(),\n",
        "            nn.Conv1d(32, 16, kernel_size=kernelsize, stride=1, padding='same'),\n",
        "            nn.BatchNorm1d(16),\n",
        "            #nn.ReLU(),\n",
        "            nn.Conv1d(16, 32, kernel_size=kernelsize, stride=1, padding='same'),\n",
        "            nn.BatchNorm1d(32),\n",
        "            #nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bblock(x)\n",
        "        identity = x\n",
        "        output = out + identity  # element-wise addition for skip connection\n",
        "        return output\n",
        "\n",
        "class BasicBlockall(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BasicBlockall, self).__init__()\n",
        "        self.bblock3 = nn.Sequential(Res_BasicBlock(3), Res_BasicBlock(3))\n",
        "        self.bblock5 = nn.Sequential(Res_BasicBlock(5), Res_BasicBlock(5))\n",
        "        self.bblock7 = nn.Sequential(Res_BasicBlock(7), Res_BasicBlock(7))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out3 = self.bblock3(x)\n",
        "        out5 = self.bblock5(x)\n",
        "        out7 = self.bblock7(x)\n",
        "        out = torch.cat([out3, out5, out7], dim=1)  # concatenate along channel dimension\n",
        "        return out\n",
        "\n",
        "class OneD_ResCNN(nn.Module):\n",
        "    def __init__(self, seq_length, batch_size, n_chan):\n",
        "        super(OneD_ResCNN, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.n_chan = n_chan\n",
        "\n",
        "        self.initial_conv = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, kernel_size=5, stride=1, padding='same'),\n",
        "            nn.BatchNorm1d(32),\n",
        "            #nn.ReLU()\n",
        "        )\n",
        "        self.basic_block = BasicBlockall()\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv1d(96, 1, kernel_size=1, stride=1, padding='same'),  # Adjust channels after concatenation\n",
        "            nn.BatchNorm1d(1),\n",
        "            #nn.ReLU()\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(seq_length, seq_length)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.squeeze()\n",
        "        #x = x.unsqueeze(1)\n",
        "        x = x.squeeze(1)\n",
        "        x = x.view(self.batch_size*self.n_chan, 1, -1)\n",
        "        x = self.initial_conv(x)\n",
        "        x = self.basic_block(x)\n",
        "        x = self.final_conv(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        x = x.view(self.batch_size, 1, self.n_chan, -1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "j-iFs3UvEtKk"
      },
      "id": "j-iFs3UvEtKk",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IC-U_Net"
      ],
      "metadata": {
        "id": "YJOAg4G1FVJT"
      },
      "id": "YJOAg4G1FVJT"
    },
    {
      "cell_type": "code",
      "source": [
        "class CBR(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size):\n",
        "        super().__init__()\n",
        "        padding = int((kernel_size - 1) / 2)\n",
        "\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm1d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm1d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class IC_U_NET(nn.Module):\n",
        "    def __init__(self, input_channels=18):\n",
        "        super(IC_U_NET, self).__init__()\n",
        "\n",
        "        self.enc1 = CBR(input_channels, 64, 7)\n",
        "        self.enc2 = CBR(64, 128, 7)\n",
        "        self.enc3 = CBR(128, 256, 5)\n",
        "        self.enc4 = CBR(256, 512, 3)\n",
        "        self.dec1 = CBR(512, 256, 3)\n",
        "        self.dec2 = CBR(256, 128, 3)\n",
        "        self.dec3 = CBR(128, 64, 3)\n",
        "        self.dec4 = nn.Sequential(\n",
        "            nn.Conv1d(128, 64, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(64, input_channels, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm1d(input_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.maxPool = nn.MaxPool1d(2)\n",
        "        self.tConv1 = nn.ConvTranspose1d(512, 512, kernel_size=2, stride=2)\n",
        "        self.tConv2 = nn.ConvTranspose1d(512, 256, kernel_size=2, stride=2)\n",
        "        self.tConv3 = nn.ConvTranspose1d(256, 128, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "        # Encoder: 3 1D convolutional layers\n",
        "        self.encoder = nn.Sequential(\n",
        "            self.enc1,\n",
        "            nn.MaxPool1d(2),\n",
        "            self.enc2,\n",
        "            nn.MaxPool1d(2),\n",
        "            self.enc3,\n",
        "            nn.MaxPool1d(2),\n",
        "            self.enc4,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # Decoder: 3 1D transposed convolutional layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose1d(512, 512, kernel_size=2, stride=2),  # [batch_size, 128, 128]\n",
        "            self.dec1,\n",
        "            nn.ConvTranspose1d(256, 256, kernel_size=2, stride=2),   # [batch_size, 64, 256]\n",
        "            self.dec2,\n",
        "            nn.ConvTranspose1d(128, 128, kernel_size=2, stride=2),  # [batch_size, input_channels, 512]\n",
        "            self.dec3,\n",
        "            self.dec4,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(1)\n",
        "\n",
        "        #encoder\n",
        "        skip1 = self.enc1(x)\n",
        "        x = self.maxPool(skip1)\n",
        "        skip2 = self.enc2(x)\n",
        "        x = self.maxPool(skip2)\n",
        "        skip3 = self.enc3(x)\n",
        "        x = self.maxPool(skip3)\n",
        "        x = self.enc4(x)\n",
        "\n",
        "        #decoder\n",
        "        x = self.tConv1(x)\n",
        "        x1 = self.dec1(x)\n",
        "        x = torch.cat([x1, skip3], dim=1)\n",
        "        x = self.tConv2(x)\n",
        "        x2 = self.dec2(x)\n",
        "        x = torch.cat([x2, skip2], dim=1)\n",
        "        x = self.tConv3(x)\n",
        "        x3 = self.dec3(x)\n",
        "        x = torch.cat([x3, skip1], dim=1)\n",
        "        x = self.dec4(x)\n",
        "        return x.unsqueeze(1)"
      ],
      "metadata": {
        "id": "UubUwdjpFZnj"
      },
      "id": "UubUwdjpFZnj",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e5ef5e78",
      "metadata": {
        "id": "e5ef5e78"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f719a097",
      "metadata": {
        "id": "f719a097"
      },
      "outputs": [],
      "source": [
        "def segment_eeg(eeg, window_size=100, stride=50):\n",
        "    \"\"\" Session EEG Signal by Slinding Window \"\"\"\n",
        "    n_chan, n_timep = eeg.shape\n",
        "    tstamps, segments = [], []\n",
        "    for i in range(0, n_timep, stride):\n",
        "        seg = eeg[:,i: i + window_size]\n",
        "        if seg.shape != (n_chan, window_size):\n",
        "            break\n",
        "        segments.append(seg)\n",
        "        tstamps.append(i)\n",
        "\n",
        "    return segments, tstamps\n",
        "\n",
        "def create_dataset(x_fpath, y_fpath, fmt_terms, tmin, tmax, ch_names=None, win_size=4, stride=2):\n",
        "    \"\"\" read mne set to numpy array \"\"\"\n",
        "    x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
        "    sfreq = x_raw.info[\"sfreq\"]\n",
        "    win_size = math.ceil(win_size * sfreq)\n",
        "    stride = math.ceil(stride * sfreq)\n",
        "    nb_chan = len(x_raw.ch_names if ch_names is None else ch_names)\n",
        "    tmin = math.ceil(tmin * sfreq)\n",
        "    tmax = math.ceil(tmax * sfreq)\n",
        "\n",
        "    X = np.zeros((0, nb_chan, win_size), dtype=np.float32)\n",
        "    y = np.zeros((0, nb_chan, win_size), dtype=np.float32)\n",
        "    for fmt_term in fmt_terms:\n",
        "        x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
        "        y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
        "        if len(x_raw.ch_names) != len(y_raw.ch_names):\n",
        "            raise ValueError(f\"EEG channel should be matched, found {len(x_raw.ch_names)} and {len(y_raw.ch_names)}\")\n",
        "\n",
        "        x_content = x_raw[:, tmin: tmax][0]\n",
        "        y_content = y_raw[:, tmin: tmax][0]\n",
        "\n",
        "        #np.shape(x_content)\n",
        "        #plt.hist(x_content*1e+6)\n",
        "        #plt.show()\n",
        "\n",
        "        if ch_names is not None:  # channel selection\n",
        "            picks = [x_raw.ch_names.index(ch) for ch in ch_names]\n",
        "            x_content = x_content[picks]\n",
        "            y_content = y_content[picks]\n",
        "\n",
        "        x_seg = np.array(segment_eeg(x_content, win_size, stride)[0])\n",
        "        y_seg = np.array(segment_eeg(y_content, win_size, stride)[0])\n",
        "        X = np.append(X, np.array(x_seg), axis=0)\n",
        "        y = np.append(y, np.array(y_seg), axis=0)\n",
        "    return X*1e+6, y*1e+6    #TODO\n",
        "\n",
        "def calc_SNR(clean_data, noisy_data, inDezibel = True):\n",
        "    # clean data: reference data\n",
        "    # noisy data: data to measure SNR on, e.g. output of the model\n",
        "    n_chan = clean_data.shape[0]\n",
        "\n",
        "    if inDezibel:\n",
        "        return 1/n_chan * np.sum(10 * np.log10(np.linalg.norm(clean_data, axis = 1)/np.linalg.norm(clean_data-noisy_data, axis = 1)))\n",
        "    else:\n",
        "        return 1/n_chan * np.sum(np.linalg.norm(clean_data, axis = 1)**2/np.linalg.norm(clean_data-noisy_data, axis = 1)**2)\n",
        "\n",
        "\n",
        "def create_EEG_DenoiseNet_dataset(config, artifact_type, debug = False):\n",
        "    #TODO what about the upsampling?\n",
        "\n",
        "    np.random.seed(0)  # for reproducibility\n",
        "    snr_eog = np.linspace(-7,2, 10) # in dB\n",
        "    snr_emg = np.linspace(-7,4, 12) # in dB\n",
        "\n",
        "    Y = []\n",
        "    X = []\n",
        "\n",
        "    y = np.load(config['EEG_path'])        # clean segments\n",
        "\n",
        "\n",
        "    #l_sum = 0\n",
        "\n",
        "    ############### EOG ##################\n",
        "    if artifact_type == 'EOG':\n",
        "        n_EOG = np.load(config['EOG_path'])    #EOG noise segments\n",
        "        nr_eog_segs = n_EOG.shape[0]\n",
        "        selected_eeg_indices = np.random.choice(y.shape[0], nr_eog_segs, replace=False)\n",
        "        selected_eeg_segments = y[selected_eeg_indices]\n",
        "\n",
        "        #l = np.sum(x[0][:]**2)/np.sum(n_EOG[0][:]**2)/(10**(snr/5))\n",
        "        #EOG: 3400 segments, EEG: 4514 segments\n",
        "        #for i in range(nr_eog_segs):\n",
        "            #l_sum += np.linalg.norm(selected_eeg_segments[i][:])/np.linalg.norm(n_EOG[i][:])/(10**(snr/10))\n",
        "        #l = l_sum/nr_eog_segs\n",
        "        for snr in snr_eog:\n",
        "            l = np.linalg.norm(selected_eeg_segments.flatten())/np.linalg.norm(n_EOG.flatten())/(10**(snr/10))\n",
        "            x = selected_eeg_segments + l*n_EOG\n",
        "            if debug:\n",
        "                snr_check_eog = calc_SNR(np.expand_dims(selected_eeg_segments.flatten(), 0), np.expand_dims(x.flatten(), 0))\n",
        "            Y.append(selected_eeg_segments)\n",
        "            X.append(x)\n",
        "\n",
        "    elif artifact_type == 'EMG':\n",
        "    ############### EMG ##################\n",
        "        n_EMG = np.load(config['EMG_path'])    #EMG noise segments\n",
        "        nr_emg_segs = n_EMG.shape[0]\n",
        "        np.random.shuffle(n_EMG)\n",
        "        selected_eeg_indices = np.random.choice(y.shape[0], nr_emg_segs - y.shape[0], replace=False)\n",
        "        selected_eeg_segments = y[selected_eeg_indices]\n",
        "        y_expanded = np.vstack((y,selected_eeg_segments))\n",
        "        for snr in snr_emg:\n",
        "            l = np.linalg.norm(y_expanded.flatten())/np.linalg.norm(n_EMG.flatten())/(10**(snr/10))\n",
        "            x = y_expanded + l*n_EMG\n",
        "            if debug:\n",
        "                snr_check_emg = calc_SNR(np.expand_dims(y_expanded.flatten(), 0), np.expand_dims(x.flatten(), 0))\n",
        "            X.append(x)\n",
        "            Y.append(y_expanded)\n",
        "    else:\n",
        "        raise Exception(\"Wrong artifact type.\")\n",
        "\n",
        "    X = np.vstack(X)\n",
        "    Y = np.vstack(Y)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def get_rdm_EEG_segment_DenoiseNet (config, artifact_type, snr, debug=False):\n",
        "    np.random.seed(0)  # for reproducibility\n",
        "\n",
        "    y = np.load(config['EEG_path'])        # clean segments\n",
        "\n",
        "    #l_sum = 0\n",
        "\n",
        "    ############### EOG ##################\n",
        "    if artifact_type == 'EOG':\n",
        "        n_EOG = np.load(config['EOG_path'])    #EOG noise segments\n",
        "        random_idx_eeg = np.random.choice(y.shape[0], 1, replace=False)\n",
        "        random_idx_noise = np.random.choice(n_EOG.shape[0], 1, replace=False)\n",
        "        selected_clean_segment = y[random_idx_eeg]\n",
        "        selected_noise_segment = n_EOG[random_idx_noise]\n",
        "\n",
        "        l = np.linalg.norm(selected_clean_segment)/np.linalg.norm(selected_noise_segment)/(10**(snr/10))\n",
        "        x = selected_clean_segment + l*selected_noise_segment\n",
        "        if debug:\n",
        "            snr_check_eog = calc_SNR(np.expand_dims(selected_clean_segment, 0), np.expand_dims(x, 0))\n",
        "\n",
        "    elif artifact_type == 'EMG':\n",
        "    ############### EMG ##################\n",
        "        n_EMG = np.load(config['EMG_path'])    #EMG noise segments\n",
        "        random_idx_eeg = np.random.choice(y.shape[0], 1, replace=False)\n",
        "        random_idx_noise = np.random.choice(n_EMG.shape[0], 1, replace=False)\n",
        "        selected_clean_segment = y[random_idx_eeg]\n",
        "        selected_noise_segment = n_EMG[random_idx_noise]\n",
        "\n",
        "        l = np.linalg.norm(selected_clean_segment)/np.linalg.norm(selected_noise_segment)/(10**(snr/10))\n",
        "        x = selected_clean_segment + l*selected_noise_segment\n",
        "        if debug:\n",
        "            snr_check_emg = calc_SNR(np.expand_dims(selected_clean_segment, 0), np.expand_dims(x, 0))\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Wrong artifact type.\")\n",
        "\n",
        "    return x, selected_clean_segment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aebb618",
      "metadata": {
        "id": "3aebb618"
      },
      "source": [
        "# Model Tracer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "333c68ff",
      "metadata": {
        "id": "333c68ff"
      },
      "outputs": [],
      "source": [
        "class Model_Tracer():\n",
        "    def __init__(self, monitor=\"loss\", mode=\"min\", do_save=False, root=None, prefix=\"checkpoint\"):\n",
        "        if mode not in [\"min\", \"max\"]:\n",
        "            raise ValueError(\"mode can only be `min` or `max`\")\n",
        "        self.mode = mode\n",
        "        self.monitor = monitor\n",
        "        self.do_save = do_save\n",
        "        self.bound = np.inf if mode == \"min\" else (-np.inf)\n",
        "        self.root = os.path.join(expanduser(\"~\"), \"Downloads\") if root is None else root\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        if ((self.mode == \"min\" and logs[self.monitor] < self.bound) or\n",
        "            (self.mode == \"max\" and logs[self.monitor] > self.bound)\n",
        "        ):\n",
        "            print(\"Epoch {}: {} is improved from {:.6f} to {:.6f}\".format(\n",
        "                epoch, self.monitor, self.bound, logs[self.monitor]\n",
        "            ))\n",
        "            self.bound = logs[self.monitor]\n",
        "            if self.do_save:\n",
        "                filename = \"{}.pth\".format(self.prefix)\n",
        "                torch.save(logs, os.path.join(self.root, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model select\n"
      ],
      "metadata": {
        "id": "vx4VDHZnGUuG"
      },
      "id": "vx4VDHZnGUuG"
    },
    {
      "cell_type": "code",
      "source": [
        "def model_select(model_class, model_cfg):\n",
        "    if model_class == 'CLEEGN':\n",
        "        model = CLEEGN(n_chan=model_cfg['n_chan'], fs=128, N_F=model_cfg['N_F'])\n",
        "    elif model_class == 'xLSTM':\n",
        "        xlstm_cfg = model_cfg['cfg']\n",
        "        xlstm_cfg = OmegaConf.create(xlstm_cfg)\n",
        "        xlstm_cfg = from_dict(data_class=xLSTMBlockStackConfig, data=OmegaConf.to_container(xlstm_cfg), config=DaciteConfig(strict=True))\n",
        "        xlstm_stack = xLSTMBlockStack(xlstm_cfg)\n",
        "        model = xlstm_stack\n",
        "    elif model_class == 'Seq2Seq':\n",
        "        model = Seq2Seq(input_dim=model_cfg['n_chan'], hidden_dim=model_cfg['hidden_dim'], output_dim=model_cfg['n_chan'], num_layers=model_cfg['num_layers'])\n",
        "    elif model_class == 'Seq2Seq_LSTM':\n",
        "        model = Seq2SeqLSTM(input_dim=model_cfg['n_chan'], hidden_dim=model_cfg['hidden_dim'], output_dim=model_cfg['n_chan'], num_layers=model_cfg['num_layers'])\n",
        "    elif model_class == 'LSTM':\n",
        "        model = LSTM(input_dim=model_cfg['n_chan'], hidden_dim=model_cfg['hidden_dim'], output_dim=model_cfg['n_chan'], num_layers=model_cfg['num_layers'])\n",
        "    elif model_class == 'Seq2Seq_Attention':\n",
        "        model = Seq2SeqWithAttention(input_dim=model_cfg['n_chan'], hidden_dim=model_cfg['hidden_dim'], output_dim=model_cfg['n_chan'], num_layers=model_cfg['num_layers'])\n",
        "    elif model_class == 'LSTM_Autoencoder':\n",
        "        model = LSTMAutoencoder(input_dim=model_cfg['n_chan'], hidden_dim=model_cfg['hidden_dim'], latent_dim=model_cfg['latent_dim'], output_dim=model_cfg['n_chan'], num_layers=model_cfg['num_layers'])\n",
        "    elif model_class == 'Transformer':\n",
        "        model = TransformerDenoiser(input_dim=model_cfg['n_chan'], embed_dim = model_cfg['embed_dim'], num_heads = model_cfg['num_heads'], num_layers = model_cfg['num_layers'], hidden_dim = model_cfg['hidden_dim'], dropout = model_cfg['dropout'], max_len = model_cfg['max_len'])\n",
        "    elif model_class == 'Autoencoder_CNN':\n",
        "        model = ConvAutoencoder(input_channels=model_cfg['n_chan'])\n",
        "    elif model_class == 'Autoencoder_CNN_Compress':\n",
        "        model = ConvAutoencoder_Compress(input_channels=model_cfg['n_chan'])\n",
        "    elif model_class == 'Autoencoder_CNN_LSTM':\n",
        "        model = LSTMConvAutoencoder(input_channels=model_cfg['n_chan'], sequence_length=model_cfg['sequence_length'], hidden_dim=model_cfg['hidden_dim'], latent_dim=model_cfg['latent_dim'])\n",
        "    elif model_class == 'Autoencoder_CNN_LSTM2':\n",
        "        model = LSTMConvAutoencoder2(input_dim=model_cfg['n_chan'], hidden_dim = model_cfg['n_chan'], num_layers = model_cfg['num_layers'])\n",
        "    elif model_class == 'Autoencoder_CNN_LSTM3':\n",
        "        model = LSTMConvAutoencoder3(input_dim=model_cfg['n_chan'], num_layers = model_cfg['num_layers'])\n",
        "    elif model_class == 'Autoencoder_CNN_LSTM4':\n",
        "        model = LSTMConvAutoencoder4(input_dim=model_cfg['n_chan'], num_layers = model_cfg['num_layers'])\n",
        "    elif model_class == 'Parallel_CNN_LSTM':\n",
        "        model = Parallel_CNN_LSTM(lstm_model=LSTM(input_dim=model_cfg['n_chan'], hidden_dim=model_cfg['n_chan'], output_dim=model_cfg['n_chan'], num_layers=model_cfg['num_layers']), cnn_model=ConvAutoencoder(input_channels=model_cfg['n_chan']), n_chan=model_cfg['n_chan'], learn_concat=model_cfg['learn_concat'])\n",
        "    elif model_class == 'IC_U_Net':\n",
        "        #model = IC_U_NET(n_channels=model_cfg['n_chan'], bilinear=model_cfg['bilinear'])\n",
        "        model = IC_U_NET(input_channels=model_cfg['n_chan'])\n",
        "    elif model_class == 'OneD_Res_CNN':\n",
        "        model = OneD_ResCNN(seq_length=model_cfg['seq_length'], batch_size=model_cfg['batch_size'], n_chan=model_cfg['n_chan'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "vKSNReMiGTND"
      },
      "id": "vKSNReMiGTND",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c1d073d8",
      "metadata": {
        "id": "c1d073d8"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0edaeefa",
      "metadata": {
        "id": "0edaeefa"
      },
      "outputs": [],
      "source": [
        "def train(tra_loader, model, criterion, optimizer, model_class, normalize = False, ensemble_loss = False, use_wandb = False, verbose=1):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()  # switch to train mode\n",
        "\n",
        "    log = \"\"\n",
        "    ep_time0 = time.time()\n",
        "    epoch_loss = np.zeros((len(tra_loader), ))\n",
        "    for i, (x_batch, y_batch) in enumerate(tra_loader):\n",
        "        # print(i, x_batch.shape, y_batch.shape)\n",
        "        x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device, dtype=torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if normalize:\n",
        "            #TODO: either restore (output times std) and calc loss on restored, or calc loss on normalized and only restore at inference\n",
        "            # Calculate the standard deviation for each batch along channel and sequence dimensions\n",
        "            std_per_batch = x_batch.std(dim=(2, 3))  # Keeps the result in shape [batch_size, 1]\n",
        "            percentile_95_per_batch = torch.quantile(torch.abs(x_batch), 0.95, dim=3).squeeze(-1)\n",
        "            for j in range(std_per_batch.shape[0]):\n",
        "                x_batch[j] = x_batch[j]/percentile_95_per_batch[j]\n",
        "                y_batch[j] = y_batch[j]/percentile_95_per_batch[j]\n",
        "\n",
        "\n",
        "        if model_class == \"Seq2Seq\" or model_class == 'Transformer' or model_class == \"Seq2Seq_Attention\":\n",
        "            output = model(x_batch, y_batch)\n",
        "        else:\n",
        "            output = model(x_batch)\n",
        "\n",
        "        #if normalize:\n",
        "            #for j in range(std_per_batch.shape[0]):\n",
        "                #output[j] = output[j]*std_per_batch[j]\n",
        "\n",
        "        if ensemble_loss:\n",
        "            v_x, v_y, a_x, a_y, fft_x, fft_y = calc_vel_acc_freq(output, y_batch)\n",
        "            loss_ampl = criterion(output, y_batch)\n",
        "            loss_vel = criterion(v_x, v_y)\n",
        "            loss_acc = criterion(a_x, a_y)\n",
        "            loss_freq = criterion(fft_x, fft_y)\n",
        "            loss = loss_ampl + loss_vel + loss_acc + loss_freq\n",
        "        else:\n",
        "            loss = criterion(output, y_batch)\n",
        "\n",
        "        loss.backward()\n",
        "        #if use_wandb:\n",
        "            #log_gradients_to_wandb(model)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss[i] = loss.item()\n",
        "\n",
        "        if (np.isnan(loss.item())):\n",
        "            print(x_batch)\n",
        "            print(x_batch)\n",
        "        if verbose:\n",
        "            print(\"\\r{}\".format(\" \" * len(log)), end=\"\")\n",
        "            log = \"\\r{}/{} - {:.4f} s - loss: {:.4f} - acc: nan\".format(\n",
        "                i + 1, len(tra_loader), time.time() - ep_time0, epoch_loss[i]\n",
        "            )\n",
        "            print(log, end=\"\")\n",
        "\n",
        "            #if (i == 0 or i == len(tra_loader)-1 or i%10 == 0):\n",
        "            if (0==1):\n",
        "                x_b_nump = x_batch.numpy()\n",
        "                y_b_nump = y_batch.numpy()\n",
        "                out = output.detach().numpy()\n",
        "\n",
        "                plt.plot(x_b_nump[0,:,:][0,:], label = 'x')\n",
        "                plt.plot(y_b_nump[0,:,:][0,:], label = 'y')\n",
        "                plt.plot(out[0,:,:][0,:], label = 'out')\n",
        "                plt.legend()\n",
        "                plt.savefig(\"test.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "                plt.show()\n",
        "\n",
        "                # CLEEGN:\n",
        "                #plt.plot(x_b_nump[0,:,1,:][0,:])\n",
        "                #plt.plot(y_b_nump[0,:,1,:][0,:])\n",
        "                #plt.plot(out[0,:,1,:][0,:])\n",
        "                #plt.show()\n",
        "\n",
        "\n",
        "                # mse = np.zeros(18)\n",
        "                # for i in range(18):\n",
        "                #     plt.plot(x_b_nump[0,:,i,:][0,:])\n",
        "                #     plt.plot(y_b_nump[0,:,i,:][0,:])\n",
        "                #     plt.plot(out[0,:,i,:][0,:])\n",
        "                #     plt.show()\n",
        "                #     mse[i] = np.mean((y_b_nump[0,:,i,:][0,:]-out[0,:,i,:][0,:])**2)\n",
        "\n",
        "    return epoch_loss.mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5e04209f",
      "metadata": {
        "id": "5e04209f"
      },
      "outputs": [],
      "source": [
        "def val(val_loader, model, criterion, model_class, normalize = False, verbose=0):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval() # switch to evaluation mode\n",
        "\n",
        "    log = \"\"\n",
        "    ep_time0 = time.time()\n",
        "    epoch_loss = np.zeros((len(val_loader), ))\n",
        "    for i, (x_batch, y_batch) in enumerate(val_loader):\n",
        "        x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device, dtype=torch.float)\n",
        "\n",
        "        if normalize:\n",
        "            # Calculate the standard deviation for each batch along channel and sequence dimensions\n",
        "            std_per_batch = x_batch.std(dim=(2, 3))  # Keeps the result in shape [batch_size, 1]\n",
        "            percentile_95_per_batch = torch.quantile(torch.abs(x_batch), 0.95, dim=3).squeeze(-1)\n",
        "            for j in range(std_per_batch.shape[0]):\n",
        "                x_batch[j] = x_batch[j]/percentile_95_per_batch[j]\n",
        "                y_batch[j] = y_batch[j]/percentile_95_per_batch[j]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if model_class == \"Seq2Seq\" or model_class == \"Seq2Seq_Attention\" or model_class == 'Transformer':\n",
        "                output = model(x_batch, y_batch)\n",
        "            else:\n",
        "                output = model(x_batch)\n",
        "\n",
        "        #if normalize:\n",
        "            #for j in range(std_per_batch.shape[0]):\n",
        "                #output[j] = output[j]*std_per_batch[j]\n",
        "\n",
        "        # output = x_batch # DEBUG\n",
        "        loss = criterion(output, y_batch)\n",
        "\n",
        "        epoch_loss[i] = loss.item()\n",
        "        if verbose:\n",
        "            print(\"\\r{}\".format(\" \" * len(log)), end=\"\")\n",
        "            log = \"\\r{}/{} - {:.4f} s - loss: {:.4f} - acc: nan\".format(\n",
        "                i + 1, len(val_loader), time.time() - ep_time0, epoch_loss[i]\n",
        "            )\n",
        "            print(log, end=\"\")\n",
        "    return epoch_loss.mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log_gradients_to_wandb(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.grad is not None:\n",
        "            wandb.log({f\"grad_norms/{name}\": param.grad.norm().item()})\n",
        "\n",
        "def calc_vel_acc_freq(x, y, freq = 128):\n",
        "    dt = 1.0 / freq  # Time step\n",
        "    dt = 1.0\n",
        "    # Velocity\n",
        "    v_x = torch.diff(x, n=1, dim=-1) / dt\n",
        "    v_y = torch.diff(y, n=1, dim=-1) / dt\n",
        "\n",
        "    # Acceleration\n",
        "    a_x = torch.diff(v_x, n=1, dim=-1) / dt\n",
        "    a_y = torch.diff(v_y, n=1, dim=-1) / dt\n",
        "\n",
        "    # Pad the reconstructed velocity and acceleration for consistent size\n",
        "    v_x = F.pad(v_x, (0, 1), mode='constant')\n",
        "    v_y = F.pad(v_y, (0, 1), mode='constant')\n",
        "    a_x = F.pad(a_x, (0, 2), mode='constant')\n",
        "    a_y = F.pad(a_y, (0, 2), mode='constant')\n",
        "\n",
        "    # Frequency estimate using Fourier Transform and calculate MSE for frequency spectrum\n",
        "    fft_x = torch.abs(torch.fft.fft(x, dim=-1))\n",
        "    fft_y = torch.abs(torch.fft.fft(y, dim=-1))\n",
        "    return v_x, v_y, a_x, a_y, fft_x, fft_y"
      ],
      "metadata": {
        "id": "mYDf5rHNA2T8"
      },
      "id": "mYDf5rHNA2T8",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_WANDB = True"
      ],
      "metadata": {
        "id": "8VSw-ESpKwyv"
      },
      "id": "8VSw-ESpKwyv",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "96b577d6",
      "metadata": {
        "id": "96b577d6"
      },
      "outputs": [],
      "source": [
        "def main_fct(config = None):\n",
        "    import argparse\n",
        "\n",
        "    if USE_WANDB:\n",
        "        wandb.init(config=config)\n",
        "        config = wandb.config\n",
        "        MODEL_CLASS = config.model_class\n",
        "    else:\n",
        "        MODEL_CLASS = config['model_class']\n",
        "\n",
        "    DATASET = 'TUH'    # either 'TUH' or 'BCI' or 'DenoiseNet'\n",
        "    artifact_type = 'EOG'\n",
        "    ensemble_loss = False\n",
        "\n",
        "\n",
        "    if DATASET == 'BCI':\n",
        "        config_path = '/content/drive/My Drive/A_EEG/CLEEGN/configs/bci-challenge/config.yml'\n",
        "        model_config_path = '/content/drive/My Drive/A_EEG/CLEEGN/configs/bci-challenge/model_config.yml'\n",
        "\n",
        "    elif DATASET == 'TUH':\n",
        "        config_path = '/content/drive/My Drive/A_EEG/CLEEGN/configs/tusz/config.yml'\n",
        "        model_config_path = '/content/drive/My Drive/A_EEG/CLEEGN/configs/tusz/model_config.yml'\n",
        "\n",
        "    elif DATASET == 'DenoiseNet':\n",
        "        config_path = '/content/drive/My Drive/A_EEG/CLEEGN/configs/EEG_DenoiseNet/config.yml'\n",
        "        model_config_path = '/content/drive/My Drive/A_EEG/CLEEGN/configs/EEG_DenoiseNet/model_config.yml'\n",
        "\n",
        "\n",
        "    model_name = yaml.safe_load(Path(config_path).read_text())['model_name']\n",
        "    cfg_dataset = yaml.safe_load(Path(config_path).read_text())['Dataset']\n",
        "    cfg_general = yaml.safe_load(Path(config_path).read_text())\n",
        "    cfg_model = yaml.safe_load(Path(model_config_path).read_text())[MODEL_CLASS]\n",
        "\n",
        "    SFREQ      = cfg_dataset[\"sfreq\"]\n",
        "    normalize  = cfg_dataset[\"normalize\"]\n",
        "    NUM_EPOCHS = cfg_general['epochs']\n",
        "    BATCH_SIZE = cfg_model['batch_size']\n",
        "    LR         = cfg_model[\"learning_rate\"]\n",
        "    scheduler_type = cfg_model[\"scheduler\"]['type']\n",
        "\n",
        "    if scheduler_type == 'MultiStepLR':\n",
        "        scheduler_milestones = cfg_model[\"scheduler\"]['milestones']\n",
        "    if scheduler_type == 'MultiStepLR' or scheduler_type == 'ExponentialLR':\n",
        "        scheduler_gamma = cfg_model[\"scheduler\"]['gamma']\n",
        "\n",
        "\n",
        "    # Save path\n",
        "    if cfg_general[\"save_path\"] is None:\n",
        "        if DATASET == 'DenoiseNet':\n",
        "            SAVE_PATH = '/content/drive/My Drive/A_EEG/CLEEGN/logs/' + DATASET + '_' + artifact_type + '/' + MODEL_CLASS\n",
        "        else:\n",
        "            SAVE_PATH = '/content/drive/My Drive/A_EEG/CLEEGN/logs/' + DATASET + '/' + MODEL_CLASS\n",
        "\n",
        "        if not os.path.exists(SAVE_PATH):\n",
        "            try:\n",
        "                os.makedirs(SAVE_PATH)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to create directory '{SAVE_PATH}': {e}\")\n",
        "    else:\n",
        "        SAVE_PATH = cfg_general[\"save_path\"]\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
        "\n",
        "    if DATASET == 'TUH' or DATASET == 'BCI':\n",
        "        x_train, y_train = create_dataset(\n",
        "            os.path.join(cfg_dataset[\"x_basepath\"], cfg_dataset[\"x_fpath\"]),\n",
        "            os.path.join(cfg_dataset[\"y_basepath\"], cfg_dataset[\"y_fpath\"]),\n",
        "            cfg_dataset[\"subjects_train\"], tmin=cfg_dataset[\"tmin\"], tmax=cfg_dataset[\"tmax\"],\n",
        "            ch_names=cfg_dataset[\"ch_names\"], win_size=cfg_dataset[\"window_size\"], stride=cfg_dataset[\"stride\"]\n",
        "        )\n",
        "    elif DATASET == 'DenoiseNet':\n",
        "        x, y = create_EEG_DenoiseNet_dataset(cfg_dataset, artifact_type, debug = True)\n",
        "        x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=0, shuffle=True)\n",
        "        x_train = np.expand_dims(x_train,1)\n",
        "        y_train = np.expand_dims(y_train,1)\n",
        "        x_valid = np.expand_dims(x_valid,1)\n",
        "        y_valid = np.expand_dims(y_valid,1)\n",
        "\n",
        "\n",
        "    x_train = np2TT(np.expand_dims(x_train, axis=1))\n",
        "    y_train = np2TT(np.expand_dims(y_train, axis=1))\n",
        "\n",
        "    if MODEL_CLASS == 'xLSTM':\n",
        "        x_train, y_train = x_train.permute(0,1,3,2).squeeze(), y_train.permute(0,1,3,2).squeeze()\n",
        "\n",
        "    if DATASET == 'TUH' or DATASET == 'BCI':\n",
        "        x_valid, y_valid = create_dataset(\n",
        "            os.path.join(cfg_dataset[\"x_basepath\"], cfg_dataset[\"x_fpath\"]),\n",
        "            os.path.join(cfg_dataset[\"y_basepath\"], cfg_dataset[\"y_fpath\"]),\n",
        "            cfg_dataset[\"subjects_val\"], tmin=cfg_dataset[\"tmin\"], tmax=cfg_dataset[\"tmax\"],\n",
        "            ch_names=cfg_dataset[\"ch_names\"], win_size=cfg_dataset[\"window_size\"], stride=cfg_dataset[\"stride\"]\n",
        "        )\n",
        "\n",
        "    x_valid = np2TT(np.expand_dims(x_valid, axis=1))\n",
        "    y_valid = np2TT(np.expand_dims(y_valid, axis=1))\n",
        "\n",
        "    if MODEL_CLASS == 'xLSTM':\n",
        "        x_valid, y_valid = x_valid.permute(0,1,3,2).squeeze(), y_valid.permute(0,1,3,2).squeeze()\n",
        "\n",
        "    print(x_train.size(), y_train.size(), x_valid.size(), y_valid.size())\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "    tra_loader = torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, drop_last=True\n",
        "    )\n",
        "    validset = torch.utils.data.TensorDataset(x_valid, y_valid)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        validset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True, drop_last=True\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    model = model_select(MODEL_CLASS, cfg_model).to(device)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print ('Total # of modelparameters: ', str(total_params))\n",
        "\n",
        "    #summary(model, input_size=(BATCH_SIZE, 1, x_train.size()[2], x_train.size()[3]))\n",
        "\n",
        "    ckpts = [\n",
        "        Model_Tracer(monitor=\"loss\", mode=\"min\"),\n",
        "        Model_Tracer(monitor=\"val_loss\", mode=\"min\", do_save=True, root=SAVE_PATH, prefix= MODEL_CLASS + '_' + timestamp),\n",
        "    ]\n",
        "    criteria = nn.MSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "\n",
        "    if scheduler_type == 'MultiStepLR':\n",
        "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer = optimizer, milestones = scheduler_milestones, gamma = scheduler_gamma)\n",
        "    elif scheduler_type == 'ExponentialLR':\n",
        "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer = optimizer, gamma=scheduler_gamma)\n",
        "    else:\n",
        "        scheduler = None\n",
        "\n",
        "    tra_time0 = time.time()\n",
        "    loss_curve = {\"epoch\": [], \"loss\": [], \"val_loss\": []}\n",
        "\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        loss = train(tra_loader, model, criteria, optimizer, MODEL_CLASS, normalize, ensemble_loss, USE_WANDB)\n",
        "\n",
        "        \"\"\" validation \"\"\"\n",
        "        val_loss = val(val_loader, model, criteria, MODEL_CLASS, normalize)\n",
        "        lr = optimizer.param_groups[-1]['lr']\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        print(\"\\rEpoch {}/{} - {:.2f} s - loss: {:.4f} - val_loss: {:.4f} - lr: {:e}\".format(\n",
        "            epoch + 1, NUM_EPOCHS, time.time() - tra_time0, loss, val_loss, lr\n",
        "        ))\n",
        "        state = dict(\n",
        "            epoch=epoch + 1, min_loss=ckpts[0].bound, min_vloss=ckpts[1].bound,\n",
        "            state_dict=model.state_dict(), loss=loss, val_loss=val_loss, learning_rate=lr\n",
        "        )\n",
        "        for ckpt in ckpts:\n",
        "            ckpt.on_epoch_end(epoch + 1, state)\n",
        "\n",
        "        if USE_WANDB:\n",
        "            wandb.log({\"epoch\": epoch, \"loss\": loss, \"val_loss\": val_loss})\n",
        "\n",
        "        loss_curve[\"epoch\"].append(epoch + 1)\n",
        "        loss_curve[\"loss\"].append(loss)\n",
        "        loss_curve[\"val_loss\"].append(val_loss)\n",
        "    ### End_Of_Train\n",
        "    savemat(os.path.join(SAVE_PATH, \"loss_curve.mat\"), loss_curve)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    if USE_WANDB:\n",
        "        wandb.login()\n",
        "\n",
        "        sweep_config = {\n",
        "                'method': 'grid',\n",
        "            }\n",
        "\n",
        "        parameters_dict = {\n",
        "        'model_class': {\n",
        "            'values': ['Autoencoder_CNN_LSTM3', 'CLEEGN', 'IC_U_Net', 'OneD_Res_CNN'] #['LSTM', 'Autoencoder_CNN', 'xLSTM', 'Autoencoder_CNN_LSTM2', 'Autoencoder_CNN_LSTM3', 'Autoencoder_CNN_LSTM4', 'Parallel_CNN_LSTM', 'CLEEGN', 'IC_U_Net', 'OneD_Res_CNN']\n",
        "            },\n",
        "        }\n",
        "\n",
        "        sweep_config['parameters'] = parameters_dict\n",
        "\n",
        "        sweep_id = wandb.sweep(sweep_config, project=\"EEG_Denoising\")\n",
        "\n",
        "        wandb.agent(sweep_id, main_fct)\n",
        "    else:\n",
        "        config = {\n",
        "        'model_class': 'Autoencoder_CNN_LSTM3' #['LSTM', 'Autoencoder_CNN', 'xLSTM', 'Autoencoder_CNN_LSTM2', 'Autoencoder_CNN_LSTM3', 'Autoencoder_CNN_LSTM4', 'Parallel_CNN_LSTM', 'CLEEGN', 'IC_U_Net', 'OneD_Res_CNN']\n",
        "            }\n",
        "        main_fct(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A2kLeSRwKsA4",
        "outputId": "6cbb6cab-39c0-49aa-9cfe-f2bf3b062634"
      },
      "id": "A2kLeSRwKsA4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: fj2kcvbp\n",
            "Sweep URL: https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: imxcicdz with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_class: Autoencoder_CNN_LSTM3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241117_160144-imxcicdz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/imxcicdz' target=\"_blank\">sandy-sweep-1</a></strong> to <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/imxcicdz' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/runs/imxcicdz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 6 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 6 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 7 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 7 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 8 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 8 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 10 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 10 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 11 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 11 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 12 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 12 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 13 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 13 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 15 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 15 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 21 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 21 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 23 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 23 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 24 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 24 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 25 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 25 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 30 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 30 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3237, 1, 18, 512]) torch.Size([3237, 1, 18, 512]) torch.Size([1494, 1, 18, 512]) torch.Size([1494, 1, 18, 512])\n",
            "Total # of modelparameters:  1474450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60 - 3.84 s - loss: 0.0546 - val_loss: 0.0276 - lr: 1.000000e-03\n",
            "Epoch 1: loss is improved from inf to 0.054576\n",
            "Epoch 1: val_loss is improved from inf to 0.027574\n",
            "Epoch 2/60 - 7.80 s - loss: 0.0218 - val_loss: 0.0169 - lr: 1.000000e-03\n",
            "Epoch 2: loss is improved from 0.054576 to 0.021752\n",
            "Epoch 2: val_loss is improved from 0.027574 to 0.016929\n",
            "Epoch 3/60 - 10.28 s - loss: 0.0156 - val_loss: 0.0131 - lr: 1.000000e-03\n",
            "Epoch 3: loss is improved from 0.021752 to 0.015581\n",
            "Epoch 3: val_loss is improved from 0.016929 to 0.013124\n",
            "Epoch 4/60 - 12.81 s - loss: 0.0124 - val_loss: 0.0103 - lr: 1.000000e-03\n",
            "Epoch 4: loss is improved from 0.015581 to 0.012438\n",
            "Epoch 4: val_loss is improved from 0.013124 to 0.010288\n",
            "Epoch 5/60 - 15.31 s - loss: 0.0105 - val_loss: 0.0086 - lr: 1.000000e-03\n",
            "Epoch 5: loss is improved from 0.012438 to 0.010476\n",
            "Epoch 5: val_loss is improved from 0.010288 to 0.008592\n",
            "Epoch 6/60 - 18.14 s - loss: 0.0087 - val_loss: 0.0077 - lr: 1.000000e-03\n",
            "Epoch 6: loss is improved from 0.010476 to 0.008701\n",
            "Epoch 6: val_loss is improved from 0.008592 to 0.007650\n",
            "Epoch 7/60 - 22.10 s - loss: 0.0077 - val_loss: 0.0071 - lr: 1.000000e-03\n",
            "Epoch 7: loss is improved from 0.008701 to 0.007698\n",
            "Epoch 7: val_loss is improved from 0.007650 to 0.007145\n",
            "Epoch 8/60 - 24.74 s - loss: 0.0070 - val_loss: 0.0067 - lr: 1.000000e-03\n",
            "Epoch 8: loss is improved from 0.007698 to 0.007006\n",
            "Epoch 8: val_loss is improved from 0.007145 to 0.006669\n",
            "Epoch 9/60 - 27.30 s - loss: 0.0062 - val_loss: 0.0056 - lr: 1.000000e-03\n",
            "Epoch 9: loss is improved from 0.007006 to 0.006152\n",
            "Epoch 9: val_loss is improved from 0.006669 to 0.005614\n",
            "Epoch 10/60 - 29.82 s - loss: 0.0058 - val_loss: 0.0059 - lr: 1.000000e-03\n",
            "Epoch 10: loss is improved from 0.006152 to 0.005769\n",
            "Epoch 11/60 - 32.30 s - loss: 0.0067 - val_loss: 0.0055 - lr: 1.000000e-03\n",
            "Epoch 11: val_loss is improved from 0.005614 to 0.005529\n",
            "Epoch 12/60 - 36.11 s - loss: 0.0052 - val_loss: 0.0050 - lr: 1.000000e-03\n",
            "Epoch 12: loss is improved from 0.005769 to 0.005199\n",
            "Epoch 12: val_loss is improved from 0.005529 to 0.004975\n",
            "Epoch 13/60 - 40.06 s - loss: 0.0046 - val_loss: 0.0048 - lr: 1.000000e-03\n",
            "Epoch 13: loss is improved from 0.005199 to 0.004610\n",
            "Epoch 13: val_loss is improved from 0.004975 to 0.004782\n",
            "Epoch 14/60 - 43.90 s - loss: 0.0044 - val_loss: 0.0040 - lr: 1.000000e-03\n",
            "Epoch 14: loss is improved from 0.004610 to 0.004354\n",
            "Epoch 14: val_loss is improved from 0.004782 to 0.004040\n",
            "Epoch 15/60 - 46.87 s - loss: 0.0039 - val_loss: 0.0038 - lr: 1.000000e-03\n",
            "Epoch 15: loss is improved from 0.004354 to 0.003916\n",
            "Epoch 15: val_loss is improved from 0.004040 to 0.003805\n",
            "Epoch 16/60 - 49.44 s - loss: 0.0035 - val_loss: 0.0033 - lr: 1.000000e-03\n",
            "Epoch 16: loss is improved from 0.003916 to 0.003466\n",
            "Epoch 16: val_loss is improved from 0.003805 to 0.003334\n",
            "Epoch 17/60 - 53.27 s - loss: 0.0033 - val_loss: 0.0029 - lr: 1.000000e-03\n",
            "Epoch 17: loss is improved from 0.003466 to 0.003255\n",
            "Epoch 17: val_loss is improved from 0.003334 to 0.002947\n",
            "Epoch 18/60 - 57.09 s - loss: 0.0030 - val_loss: 0.0028 - lr: 1.000000e-03\n",
            "Epoch 18: loss is improved from 0.003255 to 0.002993\n",
            "Epoch 18: val_loss is improved from 0.002947 to 0.002800\n",
            "Epoch 19/60 - 59.67 s - loss: 0.0027 - val_loss: 0.0026 - lr: 1.000000e-03\n",
            "Epoch 19: loss is improved from 0.002993 to 0.002714\n",
            "Epoch 19: val_loss is improved from 0.002800 to 0.002621\n",
            "Epoch 20/60 - 62.20 s - loss: 0.0025 - val_loss: 0.0024 - lr: 1.000000e-03\n",
            "Epoch 20: loss is improved from 0.002714 to 0.002485\n",
            "Epoch 20: val_loss is improved from 0.002621 to 0.002395\n",
            "Epoch 21/60 - 64.77 s - loss: 0.0024 - val_loss: 0.0022 - lr: 1.000000e-03\n",
            "Epoch 21: loss is improved from 0.002485 to 0.002419\n",
            "Epoch 21: val_loss is improved from 0.002395 to 0.002245\n",
            "Epoch 22/60 - 67.73 s - loss: 0.0022 - val_loss: 0.0021 - lr: 1.000000e-03\n",
            "Epoch 22: loss is improved from 0.002419 to 0.002211\n",
            "Epoch 22: val_loss is improved from 0.002245 to 0.002081\n",
            "Epoch 23/60 - 71.74 s - loss: 0.0021 - val_loss: 0.0018 - lr: 1.000000e-03\n",
            "Epoch 23: loss is improved from 0.002211 to 0.002108\n",
            "Epoch 23: val_loss is improved from 0.002081 to 0.001840\n",
            "Epoch 24/60 - 74.37 s - loss: 0.0019 - val_loss: 0.0018 - lr: 1.000000e-03\n",
            "Epoch 24: loss is improved from 0.002108 to 0.001939\n",
            "Epoch 24: val_loss is improved from 0.001840 to 0.001782\n",
            "Epoch 25/60 - 76.86 s - loss: 0.0018 - val_loss: 0.0017 - lr: 1.000000e-03\n",
            "Epoch 25: loss is improved from 0.001939 to 0.001806\n",
            "Epoch 25: val_loss is improved from 0.001782 to 0.001686\n",
            "Epoch 26/60 - 79.40 s - loss: 0.0018 - val_loss: 0.0017 - lr: 1.000000e-03\n",
            "Epoch 26: loss is improved from 0.001806 to 0.001752\n",
            "Epoch 26: val_loss is improved from 0.001686 to 0.001684\n",
            "Epoch 27/60 - 81.92 s - loss: 0.0017 - val_loss: 0.0016 - lr: 1.000000e-03\n",
            "Epoch 27: loss is improved from 0.001752 to 0.001734\n",
            "Epoch 27: val_loss is improved from 0.001684 to 0.001589\n",
            "Epoch 28/60 - 85.81 s - loss: 0.0015 - val_loss: 0.0016 - lr: 1.000000e-03\n",
            "Epoch 28: loss is improved from 0.001734 to 0.001539\n",
            "Epoch 28: val_loss is improved from 0.001589 to 0.001578\n",
            "Epoch 29/60 - 89.34 s - loss: 0.0015 - val_loss: 0.0014 - lr: 1.000000e-03\n",
            "Epoch 29: loss is improved from 0.001539 to 0.001530\n",
            "Epoch 29: val_loss is improved from 0.001578 to 0.001429\n",
            "Epoch 30/60 - 91.88 s - loss: 0.0014 - val_loss: 0.0013 - lr: 1.000000e-03\n",
            "Epoch 30: loss is improved from 0.001530 to 0.001438\n",
            "Epoch 30: val_loss is improved from 0.001429 to 0.001264\n",
            "Epoch 31/60 - 94.42 s - loss: 0.0014 - val_loss: 0.0013 - lr: 1.000000e-03\n",
            "Epoch 31: loss is improved from 0.001438 to 0.001366\n",
            "Epoch 32/60 - 96.89 s - loss: 0.0016 - val_loss: 0.0014 - lr: 1.000000e-03\n",
            "Epoch 33/60 - 100.27 s - loss: 0.0013 - val_loss: 0.0012 - lr: 1.000000e-03\n",
            "Epoch 33: loss is improved from 0.001366 to 0.001315\n",
            "Epoch 33: val_loss is improved from 0.001264 to 0.001213\n",
            "Epoch 34/60 - 104.10 s - loss: 0.0012 - val_loss: 0.0011 - lr: 1.000000e-03\n",
            "Epoch 34: loss is improved from 0.001315 to 0.001170\n",
            "Epoch 34: val_loss is improved from 0.001213 to 0.001142\n",
            "Epoch 35/60 - 106.70 s - loss: 0.0012 - val_loss: 0.0015 - lr: 1.000000e-03\n",
            "Epoch 35: loss is improved from 0.001170 to 0.001161\n",
            "Epoch 36/60 - 109.20 s - loss: 0.0019 - val_loss: 0.0014 - lr: 1.000000e-03\n",
            "Epoch 37/60 - 111.74 s - loss: 0.0015 - val_loss: 0.0012 - lr: 1.000000e-03\n",
            "Epoch 38/60 - 114.58 s - loss: 0.0011 - val_loss: 0.0011 - lr: 1.000000e-03\n",
            "Epoch 38: loss is improved from 0.001161 to 0.001111\n",
            "Epoch 38: val_loss is improved from 0.001142 to 0.001100\n",
            "Epoch 39/60 - 118.62 s - loss: 0.0010 - val_loss: 0.0011 - lr: 1.000000e-03\n",
            "Epoch 39: loss is improved from 0.001111 to 0.001023\n",
            "Epoch 40/60 - 121.29 s - loss: 0.0010 - val_loss: 0.0010 - lr: 1.000000e-03\n",
            "Epoch 40: loss is improved from 0.001023 to 0.000975\n",
            "Epoch 40: val_loss is improved from 0.001100 to 0.001022\n",
            "Epoch 41/60 - 123.82 s - loss: 0.0010 - val_loss: 0.0011 - lr: 1.000000e-03\n",
            "Epoch 42/60 - 126.37 s - loss: 0.0015 - val_loss: 0.0010 - lr: 1.000000e-03\n",
            "Epoch 42: val_loss is improved from 0.001022 to 0.001005\n",
            "Epoch 43/60 - 129.07 s - loss: 0.0010 - val_loss: 0.0010 - lr: 1.000000e-03\n",
            "Epoch 43: loss is improved from 0.000975 to 0.000965\n",
            "Epoch 44/60 - 133.13 s - loss: 0.0009 - val_loss: 0.0011 - lr: 1.000000e-03\n",
            "Epoch 44: loss is improved from 0.000965 to 0.000860\n",
            "Epoch 45/60 - 135.85 s - loss: 0.0012 - val_loss: 0.0009 - lr: 1.000000e-03\n",
            "Epoch 45: val_loss is improved from 0.001005 to 0.000941\n",
            "Epoch 46/60 - 138.39 s - loss: 0.0010 - val_loss: 0.0010 - lr: 1.000000e-03\n",
            "Epoch 47/60 - 140.91 s - loss: 0.0009 - val_loss: 0.0010 - lr: 1.000000e-03\n",
            "Epoch 48/60 - 143.41 s - loss: 0.0008 - val_loss: 0.0009 - lr: 1.000000e-03\n",
            "Epoch 48: loss is improved from 0.000860 to 0.000838\n",
            "Epoch 48: val_loss is improved from 0.000941 to 0.000901\n",
            "Epoch 49/60 - 147.29 s - loss: 0.0008 - val_loss: 0.0009 - lr: 1.000000e-03\n",
            "Epoch 49: loss is improved from 0.000838 to 0.000767\n",
            "Epoch 50/60 - 151.16 s - loss: 0.0011 - val_loss: 0.0008 - lr: 1.000000e-03\n",
            "Epoch 50: val_loss is improved from 0.000901 to 0.000828\n",
            "Epoch 51/60 - 153.72 s - loss: 0.0007 - val_loss: 0.0009 - lr: 1.000000e-03\n",
            "Epoch 51: loss is improved from 0.000767 to 0.000733\n",
            "Epoch 52/60 - 156.27 s - loss: 0.0008 - val_loss: 0.0008 - lr: 1.000000e-03\n",
            "Epoch 53/60 - 158.87 s - loss: 0.0008 - val_loss: 0.0008 - lr: 1.000000e-03\n",
            "Epoch 53: val_loss is improved from 0.000828 to 0.000805\n",
            "Epoch 54/60 - 161.92 s - loss: 0.0015 - val_loss: 0.0013 - lr: 1.000000e-03\n",
            "Epoch 55/60 - 165.71 s - loss: 0.0011 - val_loss: 0.0009 - lr: 1.000000e-03\n",
            "Epoch 56/60 - 168.23 s - loss: 0.0008 - val_loss: 0.0008 - lr: 1.000000e-03\n",
            "Epoch 56: val_loss is improved from 0.000805 to 0.000757\n",
            "Epoch 57/60 - 170.83 s - loss: 0.0007 - val_loss: 0.0007 - lr: 1.000000e-03\n",
            "Epoch 57: loss is improved from 0.000733 to 0.000727\n",
            "Epoch 57: val_loss is improved from 0.000757 to 0.000670\n",
            "Epoch 58/60 - 173.40 s - loss: 0.0007 - val_loss: 0.0007 - lr: 1.000000e-03\n",
            "Epoch 58: loss is improved from 0.000727 to 0.000665\n",
            "Epoch 59/60 - 176.23 s - loss: 0.0006 - val_loss: 0.0007 - lr: 1.000000e-03\n",
            "Epoch 59: loss is improved from 0.000665 to 0.000618\n",
            "Epoch 60/60 - 180.15 s - loss: 0.0006 - val_loss: 0.0007 - lr: 1.000000e-03\n",
            "Epoch 60: loss is improved from 0.000618 to 0.000591\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇███</td></tr><tr><td>loss</td><td>█▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>59</td></tr><tr><td>loss</td><td>0.00059</td></tr><tr><td>val_loss</td><td>0.00069</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sandy-sweep-1</strong> at: <a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/imxcicdz' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/runs/imxcicdz</a><br/> View project at: <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241117_160144-imxcicdz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0by75vlj with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_class: CLEEGN\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241117_160549-0by75vlj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/0by75vlj' target=\"_blank\">astral-sweep-2</a></strong> to <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/0by75vlj' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/runs/0by75vlj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 6 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 6 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 7 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 7 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 8 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 8 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 10 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 10 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 11 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 11 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 12 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 12 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 13 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 13 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 15 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 15 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 21 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 21 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 23 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 23 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 24 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 24 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 25 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 25 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 30 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 30 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3237, 1, 18, 512]) torch.Size([3237, 1, 18, 512]) torch.Size([1494, 1, 18, 512]) torch.Size([1494, 1, 18, 512])\n",
            "Total # of modelparameters:  10767\n",
            "Epoch 1/60 - 4.80 s - loss: 0.0598 - val_loss: 0.0305 - lr: 1.000000e-03\n",
            "Epoch 1: loss is improved from inf to 0.059767\n",
            "Epoch 1: val_loss is improved from inf to 0.030513\n",
            "Epoch 2/60 - 9.52 s - loss: 0.0214 - val_loss: 0.0192 - lr: 8.000000e-04\n",
            "Epoch 2: loss is improved from 0.059767 to 0.021446\n",
            "Epoch 2: val_loss is improved from 0.030513 to 0.019178\n",
            "Epoch 3/60 - 15.12 s - loss: 0.0159 - val_loss: 0.0147 - lr: 6.400000e-04\n",
            "Epoch 3: loss is improved from 0.021446 to 0.015946\n",
            "Epoch 3: val_loss is improved from 0.019178 to 0.014655\n",
            "Epoch 4/60 - 19.81 s - loss: 0.0131 - val_loss: 0.0123 - lr: 5.120000e-04\n",
            "Epoch 4: loss is improved from 0.015946 to 0.013105\n",
            "Epoch 4: val_loss is improved from 0.014655 to 0.012325\n",
            "Epoch 5/60 - 24.58 s - loss: 0.0113 - val_loss: 0.0098 - lr: 4.096000e-04\n",
            "Epoch 5: loss is improved from 0.013105 to 0.011328\n",
            "Epoch 5: val_loss is improved from 0.012325 to 0.009798\n",
            "Epoch 6/60 - 30.18 s - loss: 0.0102 - val_loss: 0.0090 - lr: 3.276800e-04\n",
            "Epoch 6: loss is improved from 0.011328 to 0.010164\n",
            "Epoch 6: val_loss is improved from 0.009798 to 0.008990\n",
            "Epoch 7/60 - 34.92 s - loss: 0.0094 - val_loss: 0.0081 - lr: 2.621440e-04\n",
            "Epoch 7: loss is improved from 0.010164 to 0.009408\n",
            "Epoch 7: val_loss is improved from 0.008990 to 0.008142\n",
            "Epoch 8/60 - 39.69 s - loss: 0.0088 - val_loss: 0.0074 - lr: 2.097152e-04\n",
            "Epoch 8: loss is improved from 0.009408 to 0.008834\n",
            "Epoch 8: val_loss is improved from 0.008142 to 0.007408\n",
            "Epoch 9/60 - 45.39 s - loss: 0.0086 - val_loss: 0.0070 - lr: 1.677722e-04\n",
            "Epoch 9: loss is improved from 0.008834 to 0.008592\n",
            "Epoch 9: val_loss is improved from 0.007408 to 0.006997\n",
            "Epoch 10/60 - 50.10 s - loss: 0.0083 - val_loss: 0.0068 - lr: 1.342177e-04\n",
            "Epoch 10: loss is improved from 0.008592 to 0.008273\n",
            "Epoch 10: val_loss is improved from 0.006997 to 0.006849\n",
            "Epoch 11/60 - 54.85 s - loss: 0.0080 - val_loss: 0.0066 - lr: 1.073742e-04\n",
            "Epoch 11: loss is improved from 0.008273 to 0.008006\n",
            "Epoch 11: val_loss is improved from 0.006849 to 0.006585\n",
            "Epoch 12/60 - 60.43 s - loss: 0.0079 - val_loss: 0.0064 - lr: 8.589935e-05\n",
            "Epoch 12: loss is improved from 0.008006 to 0.007894\n",
            "Epoch 12: val_loss is improved from 0.006585 to 0.006366\n",
            "Epoch 13/60 - 65.08 s - loss: 0.0077 - val_loss: 0.0064 - lr: 6.871948e-05\n",
            "Epoch 13: loss is improved from 0.007894 to 0.007745\n",
            "Epoch 14/60 - 69.73 s - loss: 0.0077 - val_loss: 0.0060 - lr: 5.497558e-05\n",
            "Epoch 14: loss is improved from 0.007745 to 0.007659\n",
            "Epoch 14: val_loss is improved from 0.006366 to 0.005987\n",
            "Epoch 15/60 - 75.21 s - loss: 0.0075 - val_loss: 0.0061 - lr: 4.398047e-05\n",
            "Epoch 15: loss is improved from 0.007659 to 0.007542\n",
            "Epoch 16/60 - 79.89 s - loss: 0.0075 - val_loss: 0.0060 - lr: 3.518437e-05\n",
            "Epoch 16: loss is improved from 0.007542 to 0.007508\n",
            "Epoch 17/60 - 84.64 s - loss: 0.0074 - val_loss: 0.0058 - lr: 2.814750e-05\n",
            "Epoch 17: loss is improved from 0.007508 to 0.007437\n",
            "Epoch 17: val_loss is improved from 0.005987 to 0.005813\n",
            "Epoch 18/60 - 90.23 s - loss: 0.0074 - val_loss: 0.0065 - lr: 2.251800e-05\n",
            "Epoch 18: loss is improved from 0.007437 to 0.007351\n",
            "Epoch 19/60 - 94.87 s - loss: 0.0073 - val_loss: 0.0060 - lr: 1.801440e-05\n",
            "Epoch 19: loss is improved from 0.007351 to 0.007322\n",
            "Epoch 20/60 - 99.53 s - loss: 0.0073 - val_loss: 0.0061 - lr: 1.441152e-05\n",
            "Epoch 20: loss is improved from 0.007322 to 0.007277\n",
            "Epoch 21/60 - 105.04 s - loss: 0.0073 - val_loss: 0.0059 - lr: 1.152922e-05\n",
            "Epoch 22/60 - 109.72 s - loss: 0.0073 - val_loss: 0.0059 - lr: 9.223372e-06\n",
            "Epoch 23/60 - 114.45 s - loss: 0.0073 - val_loss: 0.0057 - lr: 7.378698e-06\n",
            "Epoch 23: loss is improved from 0.007277 to 0.007271\n",
            "Epoch 23: val_loss is improved from 0.005813 to 0.005660\n",
            "Epoch 24/60 - 119.95 s - loss: 0.0073 - val_loss: 0.0063 - lr: 5.902958e-06\n",
            "Epoch 24: loss is improved from 0.007271 to 0.007269\n",
            "Epoch 25/60 - 124.64 s - loss: 0.0073 - val_loss: 0.0058 - lr: 4.722366e-06\n",
            "Epoch 26/60 - 129.32 s - loss: 0.0072 - val_loss: 0.0056 - lr: 3.777893e-06\n",
            "Epoch 26: loss is improved from 0.007269 to 0.007223\n",
            "Epoch 26: val_loss is improved from 0.005660 to 0.005564\n",
            "Epoch 27/60 - 134.75 s - loss: 0.0072 - val_loss: 0.0056 - lr: 3.022315e-06\n",
            "Epoch 27: loss is improved from 0.007223 to 0.007197\n",
            "Epoch 28/60 - 139.43 s - loss: 0.0072 - val_loss: 0.0057 - lr: 2.417852e-06\n",
            "Epoch 29/60 - 144.10 s - loss: 0.0072 - val_loss: 0.0059 - lr: 1.934281e-06\n",
            "Epoch 29: loss is improved from 0.007197 to 0.007174\n",
            "Epoch 30/60 - 149.67 s - loss: 0.0072 - val_loss: 0.0056 - lr: 1.547425e-06\n",
            "Epoch 30: loss is improved from 0.007174 to 0.007166\n",
            "Epoch 31/60 - 154.35 s - loss: 0.0072 - val_loss: 0.0055 - lr: 1.237940e-06\n",
            "Epoch 31: val_loss is improved from 0.005564 to 0.005525\n",
            "Epoch 32/60 - 159.04 s - loss: 0.0072 - val_loss: 0.0056 - lr: 9.903520e-07\n",
            "Epoch 33/60 - 164.59 s - loss: 0.0072 - val_loss: 0.0061 - lr: 7.922816e-07\n",
            "Epoch 34/60 - 169.25 s - loss: 0.0072 - val_loss: 0.0057 - lr: 6.338253e-07\n",
            "Epoch 35/60 - 173.94 s - loss: 0.0072 - val_loss: 0.0060 - lr: 5.070602e-07\n",
            "Epoch 36/60 - 179.47 s - loss: 0.0072 - val_loss: 0.0056 - lr: 4.056482e-07\n",
            "Epoch 37/60 - 184.14 s - loss: 0.0072 - val_loss: 0.0059 - lr: 3.245186e-07\n",
            "Epoch 38/60 - 188.82 s - loss: 0.0072 - val_loss: 0.0055 - lr: 2.596148e-07\n",
            "Epoch 39/60 - 194.34 s - loss: 0.0072 - val_loss: 0.0056 - lr: 2.076919e-07\n",
            "Epoch 40/60 - 199.01 s - loss: 0.0072 - val_loss: 0.0058 - lr: 1.661535e-07\n",
            "Epoch 41/60 - 203.68 s - loss: 0.0072 - val_loss: 0.0055 - lr: 1.329228e-07\n",
            "Epoch 42/60 - 209.26 s - loss: 0.0072 - val_loss: 0.0056 - lr: 1.063382e-07\n",
            "Epoch 43/60 - 213.96 s - loss: 0.0072 - val_loss: 0.0056 - lr: 8.507059e-08\n",
            "Epoch 44/60 - 218.68 s - loss: 0.0072 - val_loss: 0.0056 - lr: 6.805647e-08\n",
            "Epoch 45/60 - 224.19 s - loss: 0.0071 - val_loss: 0.0055 - lr: 5.444518e-08\n",
            "Epoch 45: loss is improved from 0.007166 to 0.007143\n",
            "Epoch 45: val_loss is improved from 0.005525 to 0.005501\n",
            "Epoch 46/60 - 228.87 s - loss: 0.0072 - val_loss: 0.0055 - lr: 4.355614e-08\n",
            "Epoch 47/60 - 233.56 s - loss: 0.0072 - val_loss: 0.0057 - lr: 3.484491e-08\n",
            "Epoch 48/60 - 239.12 s - loss: 0.0072 - val_loss: 0.0055 - lr: 2.787593e-08\n",
            "Epoch 49/60 - 243.80 s - loss: 0.0072 - val_loss: 0.0056 - lr: 2.230075e-08\n",
            "Epoch 50/60 - 248.49 s - loss: 0.0072 - val_loss: 0.0057 - lr: 1.784060e-08\n",
            "Epoch 51/60 - 253.85 s - loss: 0.0072 - val_loss: 0.0058 - lr: 1.427248e-08\n",
            "Epoch 52/60 - 258.55 s - loss: 0.0072 - val_loss: 0.0057 - lr: 1.141798e-08\n",
            "Epoch 53/60 - 263.19 s - loss: 0.0072 - val_loss: 0.0060 - lr: 9.134385e-09\n",
            "Epoch 54/60 - 268.70 s - loss: 0.0072 - val_loss: 0.0056 - lr: 7.307508e-09\n",
            "Epoch 55/60 - 273.38 s - loss: 0.0072 - val_loss: 0.0057 - lr: 5.846007e-09\n",
            "Epoch 56/60 - 278.05 s - loss: 0.0072 - val_loss: 0.0062 - lr: 4.676805e-09\n",
            "Epoch 57/60 - 283.47 s - loss: 0.0072 - val_loss: 0.0055 - lr: 3.741444e-09\n",
            "Epoch 57: val_loss is improved from 0.005501 to 0.005493\n",
            "Epoch 58/60 - 288.18 s - loss: 0.0072 - val_loss: 0.0057 - lr: 2.993155e-09\n",
            "Epoch 59/60 - 292.87 s - loss: 0.0072 - val_loss: 0.0061 - lr: 2.394524e-09\n",
            "Epoch 60/60 - 298.37 s - loss: 0.0072 - val_loss: 0.0057 - lr: 1.915619e-09\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>59</td></tr><tr><td>loss</td><td>0.00719</td></tr><tr><td>val_loss</td><td>0.00573</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">astral-sweep-2</strong> at: <a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/0by75vlj' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/runs/0by75vlj</a><br/> View project at: <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241117_160549-0by75vlj/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vpsrjea0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_class: IC_U_Net\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241117_161059-vpsrjea0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/vpsrjea0' target=\"_blank\">dry-sweep-3</a></strong> to <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/vpsrjea0' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/runs/vpsrjea0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 6 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 6 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 7 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 7 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 8 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 8 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 10 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 10 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 11 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 11 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 12 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 12 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 13 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 13 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 15 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 15 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 21 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 21 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 23 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 23 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 24 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 24 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 25 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 25 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 30 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 30 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3237, 1, 18, 512]) torch.Size([3237, 1, 18, 512]) torch.Size([1494, 1, 18, 512]) torch.Size([1494, 1, 18, 512])\n",
            "Total # of modelparameters:  4214006\n",
            "Epoch 1/60 - 5.98 s - loss: 0.1287 - val_loss: 0.1210 - lr: 1.000000e-03\n",
            "Epoch 1: loss is improved from inf to 0.128716\n",
            "Epoch 1: val_loss is improved from inf to 0.121036\n",
            "Epoch 2/60 - 10.99 s - loss: 0.0953 - val_loss: 0.1159 - lr: 1.000000e-03\n",
            "Epoch 2: loss is improved from 0.128716 to 0.095282\n",
            "Epoch 2: val_loss is improved from 0.121036 to 0.115944\n",
            "Epoch 3/60 - 16.54 s - loss: 0.0930 - val_loss: 0.1142 - lr: 1.000000e-03\n",
            "Epoch 3: loss is improved from 0.095282 to 0.093022\n",
            "Epoch 3: val_loss is improved from 0.115944 to 0.114249\n",
            "Epoch 4/60 - 22.35 s - loss: 0.0920 - val_loss: 0.1132 - lr: 1.000000e-03\n",
            "Epoch 4: loss is improved from 0.093022 to 0.091980\n",
            "Epoch 4: val_loss is improved from 0.114249 to 0.113200\n",
            "Epoch 5/60 - 27.47 s - loss: 0.0947 - val_loss: 0.1169 - lr: 1.000000e-03\n",
            "Epoch 6/60 - 33.17 s - loss: 0.0922 - val_loss: 0.1135 - lr: 1.000000e-03\n",
            "Epoch 7/60 - 38.88 s - loss: 0.0911 - val_loss: 0.1128 - lr: 1.000000e-03\n",
            "Epoch 7: loss is improved from 0.091980 to 0.091062\n",
            "Epoch 7: val_loss is improved from 0.113200 to 0.112778\n",
            "Epoch 8/60 - 44.04 s - loss: 0.0908 - val_loss: 0.1133 - lr: 1.000000e-03\n",
            "Epoch 8: loss is improved from 0.091062 to 0.090755\n",
            "Epoch 9/60 - 49.67 s - loss: 0.0907 - val_loss: 0.1124 - lr: 1.000000e-03\n",
            "Epoch 9: loss is improved from 0.090755 to 0.090713\n",
            "Epoch 9: val_loss is improved from 0.112778 to 0.112360\n",
            "Epoch 10/60 - 55.40 s - loss: 0.0903 - val_loss: 0.1127 - lr: 1.000000e-03\n",
            "Epoch 10: loss is improved from 0.090713 to 0.090283\n",
            "Epoch 11/60 - 60.40 s - loss: 0.0900 - val_loss: 0.1116 - lr: 1.000000e-03\n",
            "Epoch 11: loss is improved from 0.090283 to 0.090027\n",
            "Epoch 11: val_loss is improved from 0.112360 to 0.111637\n",
            "Epoch 12/60 - 66.21 s - loss: 0.0899 - val_loss: 0.1116 - lr: 1.000000e-03\n",
            "Epoch 12: loss is improved from 0.090027 to 0.089905\n",
            "Epoch 12: val_loss is improved from 0.111637 to 0.111598\n",
            "Epoch 13/60 - 72.07 s - loss: 0.0897 - val_loss: 0.1117 - lr: 1.000000e-03\n",
            "Epoch 13: loss is improved from 0.089905 to 0.089662\n",
            "Epoch 14/60 - 76.97 s - loss: 0.0898 - val_loss: 0.1137 - lr: 1.000000e-03\n",
            "Epoch 15/60 - 82.54 s - loss: 0.0897 - val_loss: 0.1111 - lr: 1.000000e-03\n",
            "Epoch 15: val_loss is improved from 0.111598 to 0.111115\n",
            "Epoch 16/60 - 88.44 s - loss: 0.0894 - val_loss: 0.1121 - lr: 1.000000e-03\n",
            "Epoch 16: loss is improved from 0.089662 to 0.089413\n",
            "Epoch 17/60 - 93.37 s - loss: 0.0893 - val_loss: 0.1112 - lr: 1.000000e-03\n",
            "Epoch 17: loss is improved from 0.089413 to 0.089349\n",
            "Epoch 18/60 - 98.87 s - loss: 0.0892 - val_loss: 0.1111 - lr: 1.000000e-03\n",
            "Epoch 18: loss is improved from 0.089349 to 0.089247\n",
            "Epoch 19/60 - 104.64 s - loss: 0.0891 - val_loss: 0.1114 - lr: 1.000000e-03\n",
            "Epoch 19: loss is improved from 0.089247 to 0.089114\n",
            "Epoch 20/60 - 109.60 s - loss: 0.0891 - val_loss: 0.1110 - lr: 1.000000e-03\n",
            "Epoch 20: loss is improved from 0.089114 to 0.089111\n",
            "Epoch 20: val_loss is improved from 0.111115 to 0.111034\n",
            "Epoch 21/60 - 115.44 s - loss: 0.0890 - val_loss: 0.1111 - lr: 1.000000e-03\n",
            "Epoch 21: loss is improved from 0.089111 to 0.088998\n",
            "Epoch 22/60 - 121.30 s - loss: 0.0916 - val_loss: 0.1121 - lr: 1.000000e-03\n",
            "Epoch 23/60 - 126.28 s - loss: 0.0895 - val_loss: 0.1116 - lr: 1.000000e-03\n",
            "Epoch 24/60 - 131.84 s - loss: 0.0891 - val_loss: 0.1113 - lr: 1.000000e-03\n",
            "Epoch 25/60 - 137.78 s - loss: 0.0913 - val_loss: 0.1118 - lr: 1.000000e-03\n",
            "Epoch 26/60 - 142.80 s - loss: 0.0895 - val_loss: 0.1110 - lr: 1.000000e-03\n",
            "Epoch 26: val_loss is improved from 0.111034 to 0.111000\n",
            "Epoch 27/60 - 148.52 s - loss: 0.0892 - val_loss: 0.1115 - lr: 1.000000e-03\n",
            "Epoch 28/60 - 154.09 s - loss: 0.0891 - val_loss: 0.1111 - lr: 1.000000e-03\n",
            "Epoch 29/60 - 159.03 s - loss: 0.0889 - val_loss: 0.1112 - lr: 1.000000e-03\n",
            "Epoch 29: loss is improved from 0.088998 to 0.088904\n",
            "Epoch 30/60 - 164.61 s - loss: 0.0887 - val_loss: 0.1103 - lr: 1.000000e-03\n",
            "Epoch 30: loss is improved from 0.088904 to 0.088720\n",
            "Epoch 30: val_loss is improved from 0.111000 to 0.110311\n",
            "Epoch 31/60 - 170.56 s - loss: 0.0887 - val_loss: 0.1107 - lr: 1.000000e-03\n",
            "Epoch 31: loss is improved from 0.088720 to 0.088715\n",
            "Epoch 32/60 - 175.52 s - loss: 0.0887 - val_loss: 0.1106 - lr: 1.000000e-03\n",
            "Epoch 33/60 - 181.07 s - loss: 0.0887 - val_loss: 0.1110 - lr: 1.000000e-03\n",
            "Epoch 33: loss is improved from 0.088715 to 0.088657\n",
            "Epoch 34/60 - 186.77 s - loss: 0.0888 - val_loss: 0.1111 - lr: 1.000000e-03\n",
            "Epoch 35/60 - 191.71 s - loss: 0.0888 - val_loss: 0.1108 - lr: 1.000000e-03\n",
            "Epoch 36/60 - 197.20 s - loss: 0.0886 - val_loss: 0.1109 - lr: 1.000000e-03\n",
            "Epoch 36: loss is improved from 0.088657 to 0.088562\n",
            "Epoch 37/60 - 202.95 s - loss: 0.0885 - val_loss: 0.1110 - lr: 1.000000e-03\n",
            "Epoch 37: loss is improved from 0.088562 to 0.088476\n",
            "Epoch 38/60 - 207.88 s - loss: 0.0885 - val_loss: 0.1107 - lr: 1.000000e-03\n",
            "Epoch 39/60 - 213.43 s - loss: 0.0884 - val_loss: 0.1102 - lr: 1.000000e-03\n",
            "Epoch 39: loss is improved from 0.088476 to 0.088363\n",
            "Epoch 39: val_loss is improved from 0.110311 to 0.110167\n",
            "Epoch 40/60 - 219.13 s - loss: 0.0882 - val_loss: 0.1106 - lr: 1.000000e-03\n",
            "Epoch 40: loss is improved from 0.088363 to 0.088225\n",
            "Epoch 41/60 - 224.07 s - loss: 0.0882 - val_loss: 0.1105 - lr: 1.000000e-04\n",
            "Epoch 41: loss is improved from 0.088225 to 0.088191\n",
            "Epoch 42/60 - 229.67 s - loss: 0.0880 - val_loss: 0.1103 - lr: 1.000000e-04\n",
            "Epoch 42: loss is improved from 0.088191 to 0.088047\n",
            "Epoch 43/60 - 235.29 s - loss: 0.0881 - val_loss: 0.1102 - lr: 1.000000e-04\n",
            "Epoch 44/60 - 240.26 s - loss: 0.0881 - val_loss: 0.1101 - lr: 1.000000e-04\n",
            "Epoch 44: val_loss is improved from 0.110167 to 0.110094\n",
            "Epoch 45/60 - 246.03 s - loss: 0.0881 - val_loss: 0.1103 - lr: 1.000000e-04\n",
            "Epoch 46/60 - 251.82 s - loss: 0.0881 - val_loss: 0.1103 - lr: 1.000000e-04\n",
            "Epoch 47/60 - 256.79 s - loss: 0.0881 - val_loss: 0.1102 - lr: 1.000000e-04\n",
            "Epoch 48/60 - 262.26 s - loss: 0.0881 - val_loss: 0.1102 - lr: 1.000000e-04\n",
            "Epoch 49/60 - 268.23 s - loss: 0.0881 - val_loss: 0.1104 - lr: 1.000000e-04\n",
            "Epoch 50/60 - 273.16 s - loss: 0.0881 - val_loss: 0.1100 - lr: 1.000000e-04\n",
            "Epoch 50: val_loss is improved from 0.110094 to 0.109984\n",
            "Epoch 51/60 - 278.58 s - loss: 0.0881 - val_loss: 0.1101 - lr: 1.000000e-04\n",
            "Epoch 52/60 - 284.29 s - loss: 0.0881 - val_loss: 0.1102 - lr: 1.000000e-04\n",
            "Epoch 53/60 - 289.27 s - loss: 0.0880 - val_loss: 0.1102 - lr: 1.000000e-04\n",
            "Epoch 53: loss is improved from 0.088047 to 0.088025\n",
            "Epoch 54/60 - 294.87 s - loss: 0.0881 - val_loss: 0.1104 - lr: 1.000000e-04\n",
            "Epoch 55/60 - 300.56 s - loss: 0.0881 - val_loss: 0.1104 - lr: 1.000000e-04\n",
            "Epoch 56/60 - 305.53 s - loss: 0.0881 - val_loss: 0.1102 - lr: 1.000000e-04\n",
            "Epoch 57/60 - 310.98 s - loss: 0.0880 - val_loss: 0.1102 - lr: 1.000000e-04\n",
            "Epoch 58/60 - 316.71 s - loss: 0.0881 - val_loss: 0.1102 - lr: 1.000000e-04\n",
            "Epoch 59/60 - 321.67 s - loss: 0.0881 - val_loss: 0.1101 - lr: 1.000000e-04\n",
            "Epoch 60/60 - 327.06 s - loss: 0.0881 - val_loss: 0.1100 - lr: 1.000000e-04\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▅▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>59</td></tr><tr><td>loss</td><td>0.08807</td></tr><tr><td>val_loss</td><td>0.11004</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dry-sweep-3</strong> at: <a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/vpsrjea0' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/runs/vpsrjea0</a><br/> View project at: <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241117_161059-vpsrjea0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sxm4xrxv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_class: OneD_Res_CNN\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241117_161639-sxm4xrxv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/sxm4xrxv' target=\"_blank\">fragrant-sweep-4</a></strong> to <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/team_gtb/EEG_Denoising' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/sweeps/fj2kcvbp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/team_gtb/EEG_Denoising/runs/sxm4xrxv' target=\"_blank\">https://wandb.ai/team_gtb/EEG_Denoising/runs/sxm4xrxv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 4 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 1 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 2 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 6 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 6 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 7 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 7 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 8 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 8 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 10 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 10 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 11 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 11 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 12 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 12 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 13 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 13 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 15 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 15 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:16: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_terms[0]), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 19 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 21 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 21 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 23 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 23 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 24 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 24 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 25 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 25 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: Omitted 30 annotation(s) that were outside data range.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:27: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  x_raw = mne.io.read_raw_eeglab(x_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: Omitted 30 annotation(s) that were outside data range.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n",
            "<ipython-input-29-d62879f26def>:28: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
            "  y_raw = mne.io.read_raw_eeglab(y_fpath.format(*fmt_term), verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3237, 1, 18, 512]) torch.Size([3237, 1, 18, 512]) torch.Size([1494, 1, 18, 512]) torch.Size([1494, 1, 18, 512])\n",
            "Total # of modelparameters:  325891\n",
            "Epoch 1/60 - 13.66 s - loss: 0.0900 - val_loss: 0.0599 - lr: 1.000000e-03\n",
            "Epoch 1: loss is improved from inf to 0.089981\n",
            "Epoch 1: val_loss is improved from inf to 0.059879\n",
            "Epoch 2/60 - 27.36 s - loss: 0.0501 - val_loss: 0.0479 - lr: 1.000000e-03\n",
            "Epoch 2: loss is improved from 0.089981 to 0.050105\n",
            "Epoch 2: val_loss is improved from 0.059879 to 0.047946\n",
            "Epoch 3/60 - 41.14 s - loss: 0.0385 - val_loss: 0.0394 - lr: 1.000000e-03\n",
            "Epoch 3: loss is improved from 0.050105 to 0.038485\n",
            "Epoch 3: val_loss is improved from 0.047946 to 0.039352\n",
            "Epoch 4/60 - 55.02 s - loss: 0.0330 - val_loss: 0.0372 - lr: 1.000000e-03\n",
            "Epoch 4: loss is improved from 0.038485 to 0.032957\n",
            "Epoch 4: val_loss is improved from 0.039352 to 0.037196\n",
            "Epoch 5/60 - 68.90 s - loss: 0.0317 - val_loss: 0.0377 - lr: 1.000000e-03\n",
            "Epoch 5: loss is improved from 0.032957 to 0.031686\n",
            "Epoch 6/60 - 82.66 s - loss: 0.0313 - val_loss: 0.0357 - lr: 1.000000e-03\n",
            "Epoch 6: loss is improved from 0.031686 to 0.031342\n",
            "Epoch 6: val_loss is improved from 0.037196 to 0.035729\n",
            "Epoch 7/60 - 96.33 s - loss: 0.0306 - val_loss: 0.0359 - lr: 1.000000e-03\n",
            "Epoch 7: loss is improved from 0.031342 to 0.030578\n",
            "Epoch 8/60 - 109.93 s - loss: 0.0300 - val_loss: 0.0345 - lr: 1.000000e-03\n",
            "Epoch 8: loss is improved from 0.030578 to 0.030016\n",
            "Epoch 8: val_loss is improved from 0.035729 to 0.034550\n",
            "Epoch 9/60 - 123.50 s - loss: 0.0294 - val_loss: 0.0342 - lr: 1.000000e-03\n",
            "Epoch 9: loss is improved from 0.030016 to 0.029370\n",
            "Epoch 9: val_loss is improved from 0.034550 to 0.034156\n",
            "Epoch 10/60 - 137.22 s - loss: 0.0288 - val_loss: 0.0339 - lr: 1.000000e-03\n",
            "Epoch 10: loss is improved from 0.029370 to 0.028769\n",
            "Epoch 10: val_loss is improved from 0.034156 to 0.033901\n",
            "Epoch 11/60 - 150.86 s - loss: 0.0286 - val_loss: 0.0335 - lr: 1.000000e-03\n",
            "Epoch 11: loss is improved from 0.028769 to 0.028612\n",
            "Epoch 11: val_loss is improved from 0.033901 to 0.033469\n",
            "Epoch 12/60 - 164.74 s - loss: 0.0282 - val_loss: 0.0332 - lr: 1.000000e-03\n",
            "Epoch 12: loss is improved from 0.028612 to 0.028217\n",
            "Epoch 12: val_loss is improved from 0.033469 to 0.033250\n",
            "Epoch 13/60 - 178.66 s - loss: 0.0280 - val_loss: 0.0332 - lr: 1.000000e-03\n",
            "Epoch 13: loss is improved from 0.028217 to 0.028033\n",
            "Epoch 13: val_loss is improved from 0.033250 to 0.033163\n",
            "Epoch 14/60 - 192.63 s - loss: 0.0276 - val_loss: 0.0331 - lr: 1.000000e-03\n",
            "Epoch 14: loss is improved from 0.028033 to 0.027637\n",
            "Epoch 14: val_loss is improved from 0.033163 to 0.033070\n",
            "Epoch 15/60 - 206.29 s - loss: 0.0278 - val_loss: 0.0323 - lr: 1.000000e-03\n",
            "Epoch 15: val_loss is improved from 0.033070 to 0.032272\n",
            "Epoch 16/60 - 219.97 s - loss: 0.0274 - val_loss: 0.0323 - lr: 1.000000e-03\n",
            "Epoch 16: loss is improved from 0.027637 to 0.027378\n",
            "Epoch 17/60 - 233.47 s - loss: 0.0272 - val_loss: 0.0328 - lr: 1.000000e-03\n",
            "Epoch 17: loss is improved from 0.027378 to 0.027161\n",
            "Epoch 18/60 - 247.13 s - loss: 0.0272 - val_loss: 0.0330 - lr: 1.000000e-03\n",
            "Epoch 19/60 - 260.97 s - loss: 0.0269 - val_loss: 0.0318 - lr: 1.000000e-03\n",
            "Epoch 19: loss is improved from 0.027161 to 0.026866\n",
            "Epoch 19: val_loss is improved from 0.032272 to 0.031816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db7cec18",
      "metadata": {
        "id": "db7cec18"
      },
      "source": [
        "# TEST/INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "electrode = ['FP1', 'FP2', 'F3', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ']\n",
        "\"\"\" pyplot waveform visualization \"\"\"\n",
        "def viewARA(tstmps, data_colle, ref_i, electrode, titles=None, colors=None, alphas=None, ax=None):\n",
        "    n_data = len(data_colle)\n",
        "    titles = [\"\" for di in range(n_data)] if titles is None else titles\n",
        "    alphas = [0.5 for di in range(n_data)] if alphas is None else alphas\n",
        "    if colors is None:\n",
        "        cmap_ = plt.cm.get_cmap(\"tab20\", n_data)\n",
        "        colors = [rgb2hex(cmap_(di)) for di in range(n_data)]\n",
        "\n",
        "    picks_chs = [\"FP1\", \"FP2\", \"F7\", \"T4\", \"O2\"]\n",
        "    picks = [electrode.index(c) for c in picks_chs]\n",
        "    for di in range(n_data):\n",
        "        data_colle[di] = data_colle[di][picks, :]\n",
        "    if ax is None:\n",
        "        ax = plt.subplot()\n",
        "    for ii, ch_name in enumerate(picks_chs):\n",
        "        offset = len(picks) - ii - 1\n",
        "        norm_coef = 0.25 / np.abs(data_colle[ref_i][ii]).max()\n",
        "        for di in range(n_data):\n",
        "            eeg_dt = data_colle[di]\n",
        "            ax.plot(tstmps, eeg_dt[ii] * norm_coef + offset,\n",
        "                label=None if ii else titles[di], color=colors[di], alpha=alphas[di],\n",
        "                linewidth=3 if alphas[di] > 0.6 else 1.5, # default=1.5\n",
        "            )\n",
        "    ax.set_xlim(tstmps[0], tstmps[-1])\n",
        "    ax.set_ylim(-0.5, len(picks) - 0.5)\n",
        "\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_yticks(np.arange(len(picks)))\n",
        "    ax.set_yticklabels(picks_chs[::-1], fontsize=20)\n",
        "    ax.legend(\n",
        "        bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
        "        loc=\"lower right\", borderaxespad=0, ncol=3, fontsize=20\n",
        "    )\n",
        "\n",
        "def ar_through_model(eeg_data, model, window_size, stride):\n",
        "    model.eval()\n",
        "\n",
        "    noiseless_eeg = np.zeros(eeg_data.shape, dtype=np.float32)\n",
        "    hcoef = np.zeros(eeg_data.shape[1], dtype=np.float32)\n",
        "\n",
        "    hwin = signal.windows.hann(window_size) + 1e-9\n",
        "    for i in range(0, noiseless_eeg.shape[1], stride):\n",
        "        tstap, LAST_FRAME = i, False\n",
        "        segment = eeg_data[:, tstap: tstap + window_size]\n",
        "        if segment.shape[1] != window_size:\n",
        "            tstap = noiseless_eeg.shape[1] - window_size\n",
        "            segment = eeg_data[:, tstap:]\n",
        "            LAST_FRAME = True\n",
        "        with torch.no_grad():\n",
        "            segment = np.expand_dims(segment, axis=0)\n",
        "            data = np2TT(np.expand_dims(segment, axis=0))\n",
        "            if MODEL_CLASS == 'xLSTM':\n",
        "                data = data.permute(0,1,3,2).squeeze(0)  #ADDED\n",
        "            data = data.to(device, dtype=torch.float)\n",
        "            pred_segment = model(data)\n",
        "            if MODEL_CLASS == 'xLSTM':\n",
        "                pred_segment = pred_segment.permute(0,2,1)\n",
        "            pred_segment = np.array(pred_segment.cpu()).astype(np.float32)   #pred_segment [1, n_chan, seq_length]\n",
        "        noiseless_eeg[:, tstap: tstap + window_size] += pred_segment.squeeze() * hwin\n",
        "        hcoef[tstap: tstap + window_size] += hwin\n",
        "\n",
        "        if LAST_FRAME:\n",
        "            break\n",
        "    noiseless_eeg /= hcoef\n",
        "\n",
        "    return noiseless_eeg\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_FILE_NAME = 'OneD_Res_CNN_Nov08_10-16-12.pth'\n",
        "    TEST_DATA_PATH = '/content/drive/MyDrive/A_EEG/CLEEGN/sampleData/Data_S016_norm.mat'\n",
        "\n",
        "    model_path = os.path.join('/content/drive/MyDrive/A_EEG/CLEEGN', 'logs', DATASET, MODEL_CLASS, MODEL_FILE_NAME)\n",
        "    test_data = loadmat(TEST_DATA_PATH)\n",
        "    dt_polluted, dt_ref = test_data[\"x_test\"], test_data[\"y_test\"]\n",
        "\n",
        "    ### temporary fixed mode\n",
        "    state_path = os.path.join(model_path)\n",
        "    state = torch.load(state_path, map_location=\"cpu\")\n",
        "\n",
        "    if MODEL_CLASS == 'xLSTM':\n",
        "        xlstm_stack = xLSTMBlockStack(xlstm_cfg)\n",
        "    #model = CLEEGN(n_chan=x_train.size()[2], fs=SFREQ, N_F=x_train.size()[2]).to(device)\n",
        "    #model = xlstm_stack.to(device)\n",
        "    model = model_select(MODEL_CLASS, cfg_model).to(device)\n",
        "    model.load_state_dict(state[\"state_dict\"])\n",
        "    #model.load_state_dict(torch.load(model_path))\n",
        "    dt_cleegn = ar_through_model(\n",
        "        dt_polluted, model, math.ceil(4.0 * 128.0), math.ceil(1 * 128.0)\n",
        "    )\n",
        "\n",
        "    start = 6000\n",
        "    x_min, x_max = start, start + 500\n",
        "    x_data = dt_polluted[:, x_min: x_max]\n",
        "    y_data = dt_ref[:, x_min: x_max]\n",
        "    p_data = dt_cleegn[:, x_min: x_max]\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
        "    viewARA(\n",
        "        np.linspace(0, math.ceil(x_data.shape[-1] / 128.0), x_data.shape[-1]),\n",
        "        [x_data, y_data, y_data, p_data], 1, electrode,\n",
        "        titles=[\"Original\", \"\", \"Reference\", MODEL_CLASS], colors=[\"gray\", \"gray\", \"red\", \"blue\"], alphas=[0.5, 0, 0.8, 0.8], ax=ax\n",
        "    )\n",
        "    plt.savefig(\"test.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TWOt_wAQUqYJ"
      },
      "id": "TWOt_wAQUqYJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_FILE_NAME = 'OneD_Res_CNN_Nov13_13-35-41.pth'\n",
        "artifact_type = 'EOG'\n",
        "snr_synthetic_testData = 4 #in dezibel\n",
        "plt_interval = [0, 512]\n",
        "\n",
        "\n",
        "if DATASET == 'BCI':\n",
        "    #config_path = 'configs/BCI_KAGGLE/config.yml'\n",
        "    #model_config_path = 'configs/BCI_KAGGLE/model_config.yml'\n",
        "    electrode = ['Fp1', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'POz', 'PO8', 'O1', 'O2']\n",
        "    picks_chs = [\"Fp1\", \"Fp2\", \"F7\", \"T7\", \"O2\"]\n",
        "    TEST_DATA_PATH = 'sampleData\\Data_S14.mat'  #TBD\n",
        "\n",
        "elif DATASET == 'TUH':\n",
        "    #config_path = 'configs/TUH/config.yml'\n",
        "    #model_config_path = 'configs/TUH/model_config.yml'\n",
        "    electrode = ['FP1', 'FP2', 'F3', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ']\n",
        "    picks_chs = [\"FP1\", \"FP2\", \"F7\", \"T4\", \"O2\"]\n",
        "    TEST_DATA_PATH = '/content/drive/MyDrive/A_EEG/CLEEGN/sampleData/Data_S016_norm.mat'\n",
        "\n",
        "elif DATASET == 'DenoiseNet':\n",
        "    #config_path = 'configs/EEG_DenoiseNet/config.yml'\n",
        "    #model_config_path = 'configs/EEG_DenoiseNet/model_config.yml'\n",
        "    electrode = ['ch1']\n",
        "    picks_chs = ['ch1']\n",
        "\n",
        "\n",
        "cfg_model = yaml.safe_load(Path(model_config_path).read_text())[MODEL_CLASS]\n",
        "cfg_dataset = yaml.safe_load(Path(config_path).read_text())['Dataset']\n",
        "SFREQ      = cfg_dataset[\"sfreq\"]\n",
        "\n",
        "\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "from xlstm import (\n",
        "    xLSTMBlockStack,\n",
        "    xLSTMBlockStackConfig,\n",
        "    mLSTMBlockConfig,\n",
        "    mLSTMLayerConfig,\n",
        "    sLSTMBlockConfig,\n",
        "    sLSTMLayerConfig,\n",
        "    FeedForwardConfig,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch_dtype_map: dict[str, torch.dtype] = {\n",
        "    \"float32\": torch.float32,\n",
        "    \"bfloat16\": torch.bfloat16,\n",
        "    \"float16\": torch.float16,\n",
        "}\n",
        "xlstm_cfg = xLSTMBlockStackConfig(\n",
        "    mlstm_block=mLSTMBlockConfig(\n",
        "        mlstm=mLSTMLayerConfig(\n",
        "            conv1d_kernel_size=4, qkv_proj_blocksize=4, num_heads=3\n",
        "        )\n",
        "    ),\n",
        "    slstm_block=sLSTMBlockConfig(\n",
        "        slstm=sLSTMLayerConfig(\n",
        "            backend=\"vanilla\",\n",
        "            num_heads=1,\n",
        "            conv1d_kernel_size=4,\n",
        "            bias_init=\"powerlaw_blockdependent\",\n",
        "        ),\n",
        "        feedforward=FeedForwardConfig(proj_factor=1.3, act_fn=\"gelu\"),\n",
        "    ),\n",
        "    context_length=512,\n",
        "    num_blocks=1,\n",
        "    embedding_dim=18,\n",
        "    slstm_at=[0],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\"\"\" pyplot waveform visualization \"\"\"\n",
        "def viewARA(tstmps, data_colle, ref_i, electrode, titles=None, colors=None, alphas=None, ax=None, picks_channel=None):\n",
        "    n_data = len(data_colle)\n",
        "    titles = [\"\" for di in range(n_data)] if titles is None else titles\n",
        "    alphas = [0.5 for di in range(n_data)] if alphas is None else alphas\n",
        "    if colors is None:\n",
        "        cmap_ = plt.cm.get_cmap(\"tab20\", n_data)\n",
        "        colors = [rgb2hex(cmap_(di)) for di in range(n_data)]\n",
        "\n",
        "\n",
        "    picks = [electrode.index(c) for c in picks_chs]\n",
        "    for di in range(n_data):\n",
        "        data_colle[di] = data_colle[di][picks, :]\n",
        "    if ax is None:\n",
        "        ax = plt.subplot()\n",
        "    for ii, ch_name in enumerate(picks_chs):\n",
        "        offset = len(picks) - ii - 1\n",
        "        norm_coef = 0.25 / np.abs(data_colle[ref_i][ii]).max()\n",
        "        for di in range(n_data):\n",
        "            eeg_dt = data_colle[di]\n",
        "            ax.plot(tstmps, eeg_dt[ii] * norm_coef + offset,\n",
        "                label=None if ii else titles[di], color=colors[di], alpha=alphas[di],\n",
        "                linewidth=3 if alphas[di] > 0.6 else 1.5, # default=1.5\n",
        "            )\n",
        "    ax.set_xlim(tstmps[0], tstmps[-1])\n",
        "    ax.set_ylim(-0.5, len(picks) - 0.5)\n",
        "\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_yticks(np.arange(len(picks)))\n",
        "    ax.set_yticklabels(picks_chs[::-1], fontsize=20)\n",
        "    ax.legend(\n",
        "        bbox_to_anchor=(0, 1.02, 1, 0.2),\n",
        "        loc=\"lower right\", borderaxespad=0, ncol=3, fontsize=20\n",
        "    )\n",
        "\n",
        "def ar_through_model(eeg_data, model, window_size, stride):\n",
        "    model.eval()\n",
        "\n",
        "    noiseless_eeg = np.zeros(eeg_data.shape, dtype=np.float32)\n",
        "    hcoef = np.zeros(eeg_data.shape[1], dtype=np.float32)\n",
        "\n",
        "    hwin = signal.windows.hann(window_size) + 1e-9\n",
        "    for i in range(0, noiseless_eeg.shape[1], stride):\n",
        "        tstap, LAST_FRAME = i, False\n",
        "        segment = eeg_data[:, tstap: tstap + window_size]\n",
        "        if segment.shape[1] != window_size:\n",
        "            tstap = noiseless_eeg.shape[1] - window_size\n",
        "            segment = eeg_data[:, tstap:]\n",
        "            LAST_FRAME = True\n",
        "        with torch.no_grad():\n",
        "            segment = np.expand_dims(segment, axis=0)\n",
        "            data = np2TT(np.expand_dims(segment, axis=0))\n",
        "            if MODEL_CLASS == 'xLSTM':\n",
        "                data = data.permute(0,1,3,2).squeeze(0)  #ADDED\n",
        "            data = data.to(device, dtype=torch.float)\n",
        "            pred_segment = model(data)\n",
        "            if MODEL_CLASS == 'xLSTM':\n",
        "                pred_segment = pred_segment.permute(0,2,1)\n",
        "            pred_segment = np.array(pred_segment.cpu()).astype(np.float32)   #pred_segment [1, n_chan, seq_length]\n",
        "        noiseless_eeg[:, tstap: tstap + window_size] += pred_segment.squeeze() * hwin\n",
        "        hcoef[tstap: tstap + window_size] += hwin\n",
        "\n",
        "        if LAST_FRAME:\n",
        "            break\n",
        "    noiseless_eeg /= hcoef\n",
        "\n",
        "    return noiseless_eeg\n",
        "\n",
        "def calc_SNR(clean_data, noisy_data, inDezibel = True):\n",
        "    # clean data: reference data\n",
        "    # noisy data: data to measure SNR on, e.g. output of the model\n",
        "    n_chan = clean_data.shape[0]\n",
        "\n",
        "    if inDezibel:\n",
        "        return 1/n_chan * np.sum(10 * np.log10(np.linalg.norm(clean_data, axis = 1)/np.linalg.norm(clean_data-noisy_data, axis = 1)))\n",
        "    else:\n",
        "        return 1/n_chan * np.sum(np.linalg.norm(clean_data, axis = 1)**2/np.linalg.norm(clean_data-noisy_data, axis = 1)**2)\n",
        "\n",
        "def calc_MSE(x, y):\n",
        "    return 1/x.shape[0] * np.sum(1/x.shape[1] * np.linalg.norm(x - y, axis = 1)**2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "\n",
        "    model_path = os.path.join(os.path.abspath(os.getcwd()), 'logs', DATASET, MODEL_CLASS, MODEL_FILE_NAME)\n",
        "\n",
        "    if DATASET == 'TUH' or DATASET == 'BCI':\n",
        "        test_data = loadmat(TEST_DATA_PATH)\n",
        "        noisy_data, reference_data = test_data[\"x_test\"], test_data[\"y_test\"]\n",
        "    elif DATASET == 'DenoiseNet':\n",
        "        noisy_data, reference_data = get_rdm_EEG_segment_DenoiseNet(cfg_dataset, artifact_type, snr_synthetic_testData)\n",
        "        percentile_95 = np.quantile(np.abs(noisy_data.squeeze()), 0.95)\n",
        "        noisy_data = noisy_data/percentile_95\n",
        "        reference_data = reference_data/percentile_95\n",
        "\n",
        "\n",
        "    state_path = os.path.join(model_path)\n",
        "    state = torch.load(state_path, map_location=\"cpu\")\n",
        "\n",
        "    #xlstm_stack = xLSTMBlockStack(xlstm_cfg)\n",
        "\n",
        "    model = model_select(MODEL_CLASS, cfg_model)\n",
        "    model.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "    reconstructed_data = ar_through_model(\n",
        "        noisy_data, model, math.ceil(4.0 * 128.0), math.ceil(1 * 128.0)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    start = plt_interval[0]\n",
        "    x_min, x_max = start, start + plt_interval[1]\n",
        "    x_data = noisy_data[:, x_min: x_max]\n",
        "    y_data = reference_data[:, x_min: x_max]\n",
        "    p_data = reconstructed_data[:, x_min: x_max]\n",
        "\n",
        "    #TODO SNR, MSE berechnen und printen\n",
        "    snr = calc_SNR(y_data, p_data, inDezibel=False)\n",
        "    snr_dB = calc_SNR(y_data, p_data, inDezibel=True)\n",
        "    mse = calc_MSE(y_data, p_data)\n",
        "\n",
        "    print('Data points of segment: ' + str(p_data.shape[1]))\n",
        "    print(f'MSE: {mse:.5f}')\n",
        "    print(f'SNR: {snr_dB:.2f}dB (or {snr:.2f})')\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
        "    viewARA(\n",
        "        np.linspace(0, math.ceil(x_data.shape[-1] / 128.0), x_data.shape[-1]),\n",
        "        [x_data, y_data, y_data, p_data], 1, electrode,\n",
        "        titles=[\"Original\", \"\", \"Reference\", MODEL_CLASS], colors=[\"gray\", \"gray\", \"red\", \"blue\"], alphas=[0.5, 0, 0.8, 0.8], ax=ax,\n",
        "        picks_channel = picks_chs\n",
        "    )\n",
        "    plt.savefig(\"inference.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yPvKiHFbBqNh"
      },
      "id": "yPvKiHFbBqNh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}