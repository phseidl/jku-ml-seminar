#xLSTM hyperparameter
xLSTM:
  cfg:
    mlstm_block:
      mlstm:
        conv1d_kernel_size: 4
        qkv_proj_blocksize: 4
        num_heads: 3
    slstm_block:
      slstm:
        backend: vanilla
        num_heads: 1
        conv1d_kernel_size: 4
        bias_init: powerlaw_blockdependent
      feedforward:
        proj_factor: 1.3
        act_fn: gelu
    context_length: 512
    num_blocks: 2
    embedding_dim: 18
    slstm_at: [0,1]
  learning_rate: 0.001
  batch_size: 32
  
#CLEEGN hyperparameter
CLEEGN:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 56
  N_F: 56   #model parameter, equal to channel number


#Seq2Seq hyperparameter
Seq2Seq:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18
  hidden_dim: 18
  num_layers: 2

#Seq2SeqLSTM hyperparameter
Seq2Seq_LSTM:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18
  hidden_dim: 18
  num_layers: 2

#LSTM hyperparameter
LSTM:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18
  hidden_dim: 64
  num_layers: 2

#Seq2Seq_Attention hyperparameter
Seq2Seq_Attention:
  learning_rate: 0.01
  batch_size: 32
  n_chan: 18
  hidden_dim: 18
  num_layers: 2

#LSTM_Autoencoder hyperparameter
LSTM_Autoencoder:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18
  hidden_dim: 64
  latent_dim: 1024
  num_layers: 2

#Transformer hyperparameter
Transformer:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18
  embed_dim: 64      # Embedding dimension
  num_heads: 4       # Number of attention heads
  num_layers: 2      # Number of Transformer layers
  hidden_dim: 128    # Dimension of the feedforward network within the Transformer
  dropout: 0.1
  max_len: 512       # Maximum sequence length


#Autoencoder_CNN hyperparameter
Autoencoder_CNN:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18

#Autoencoder_CNN_Compress hyperparameter
Autoencoder_CNN_Compress:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18


#Autoencoder_CNN_LSTM hyperparameter
Autoencoder_CNN_LSTM:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18
  hidden_dim: 64 
  latent_dim: 128
  sequence_length: 512

#Autoencoder_CNN_LSTM2 hyperparameter
Autoencoder_CNN_LSTM2:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18
  sequence_length: 512 
  num_layers: 2

#Autoencoder_CNN_LSTM3 hyperparameter
Autoencoder_CNN_LSTM3:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18
  num_layers: 2


#Parallel_CNN_LSTM hyperparameter
Parallel_CNN_LSTM:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 18
  num_layers: 2
  learn_concat: False


#IC_U_Net hyperparameter
IC_U_Net:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 56

#OneD_Res_CNN hyperparameter
OneD_Res_CNN:
  learning_rate: 0.001
  batch_size: 32
  n_chan: 56
  seq_length: 512