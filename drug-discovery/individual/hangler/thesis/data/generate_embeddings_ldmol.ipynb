{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the path to your project directory\n",
    "project_path = Path(\"/Users/stefanhangler/Documents/Uni/Msc_AI/Thesis/Code.nosync/jku-ml-seminar23/drug-discovery/individual/hangler/thesis\")\n",
    "sys.path.append(str(project_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from train_autoencoder import ldmol_autoencoder\n",
    "from utils import AE_SMILES_encoder\n",
    "from rdkit import Chem\n",
    "\n",
    "class SMILESEncoder:\n",
    "    def __init__(self, checkpoint_path, tokenizer_path, config_path):\n",
    "        # Load tokenizer\n",
    "        self.tokenizer = BertTokenizer(vocab_file=tokenizer_path, do_lower_case=False, do_basic_tokenize=False)\n",
    "        # Load autoencoder model\n",
    "        self.ae_config = {\n",
    "            'bert_config_decoder': config_path + '/config_decoder.json',\n",
    "            'bert_config_encoder': config_path + '/config_encoder.json',\n",
    "            'embed_dim': 256,\n",
    "        }\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = ldmol_autoencoder(config=self.ae_config, no_train=True, tokenizer=self.tokenizer).to(self.device)\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "        self.model.load_state_dict(checkpoint['model'], strict=False)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def encode_smiles(self, smiles_list):\n",
    "        # Convert SMILES strings to canonical form\n",
    "        smiles_list = [Chem.MolToSmiles(Chem.MolFromSmiles(smile), isomericSmiles=True, canonical=True) for smile in smiles_list]\n",
    "        # Encode SMILES strings into embeddings\n",
    "        embeddings = AE_SMILES_encoder(smiles_list, self.model).permute(0, 2, 1).unsqueeze(-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Define paths\n",
    "    checkpoint_path = \"./Pretrain/checkpoint_autoencoder.ckpt\"  # Replace with your checkpoint path\n",
    "    tokenizer_path = \"./vocab_bpe_300_sc.txt\"  # Replace with your tokenizer vocab file\n",
    "    config_path = \"./\"  # Path containing config_encoder.json and config_decoder.json\n",
    "\n",
    "    # Initialize encoder\n",
    "    encoder = SMILESEncoder(checkpoint_path, tokenizer_path, config_path)\n",
    "\n",
    "    # Input SMILES strings\n",
    "    smiles_strings = [\"CCO\", \"C1=CC=CC=C1\", \"CC(=O)O\", \"C1CCCCC1\"]\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = encoder.encode_smiles(smiles_strings)\n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")  # Should show (num_smiles, embed_dim, latent_size, 1)\n",
    "    print(\"Sample embedding for first SMILES:\")\n",
    "    print(embeddings[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldmol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
