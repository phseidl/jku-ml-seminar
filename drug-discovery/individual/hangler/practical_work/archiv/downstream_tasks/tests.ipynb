{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HCAII Experiment Data\n",
    "to get an Idea about the datastructure to set up the guacamol data for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .pkl file\n",
    "import pickle\n",
    "\n",
    "with open('/Volumes/PHILIPS/coati/0.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'smiles': 'Cc1cn2c(n1)[C@@H](C(=O)NCCCN(C(=O)c1nc(O)sc1C)C1CC1)CCC2', 'zinc_id': 'ZINCtt000007JAXK', 'standardized_smiles': 'Cc1cn2c(n1)[C@@H](C(=O)NCCCN(C(=O)c1nc(O)sc1C)C1CC1)CCC2', 'atoms': array([ 6,  6,  6,  7,  6,  7,  6,  6,  8,  7,  6,  6,  6,  7,  6,  8,  6,\n",
      "        7,  6,  8, 16,  6,  6,  6,  6,  6,  6,  6,  6,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1], dtype=uint8), 'adj_mat': array([[ 0. ,  1. ,  1. ],\n",
      "       [ 1. ,  2. ,  1.5],\n",
      "       [ 2. ,  3. ,  1.5],\n",
      "       [ 3. ,  4. ,  1.5],\n",
      "       [ 4. ,  5. ,  1.5],\n",
      "       [ 4. ,  6. ,  1. ],\n",
      "       [ 6. ,  7. ,  1. ],\n",
      "       [ 7. ,  8. ,  2. ],\n",
      "       [ 7. ,  9. ,  1. ],\n",
      "       [ 9. , 10. ,  1. ],\n",
      "       [10. , 11. ,  1. ],\n",
      "       [11. , 12. ,  1. ],\n",
      "       [12. , 13. ,  1. ],\n",
      "       [13. , 14. ,  1. ],\n",
      "       [14. , 15. ,  2. ],\n",
      "       [14. , 16. ,  1. ],\n",
      "       [16. , 17. ,  1.5],\n",
      "       [17. , 18. ,  1.5],\n",
      "       [18. , 19. ,  1. ],\n",
      "       [18. , 20. ,  1.5],\n",
      "       [20. , 21. ,  1.5],\n",
      "       [21. , 22. ,  1. ],\n",
      "       [13. , 23. ,  1. ],\n",
      "       [23. , 24. ,  1. ],\n",
      "       [24. , 25. ,  1. ],\n",
      "       [ 6. , 26. ,  1. ],\n",
      "       [26. , 27. ,  1. ],\n",
      "       [27. , 28. ,  1. ],\n",
      "       [ 5. ,  1. ,  1.5],\n",
      "       [21. , 16. ,  1.5],\n",
      "       [25. , 23. ,  1. ],\n",
      "       [28. ,  3. ,  1. ],\n",
      "       [ 0. , 29. ,  1. ],\n",
      "       [ 0. , 30. ,  1. ],\n",
      "       [ 0. , 31. ,  1. ],\n",
      "       [ 2. , 32. ,  1. ],\n",
      "       [ 6. , 33. ,  1. ],\n",
      "       [ 9. , 34. ,  1. ],\n",
      "       [10. , 35. ,  1. ],\n",
      "       [10. , 36. ,  1. ],\n",
      "       [11. , 37. ,  1. ],\n",
      "       [11. , 38. ,  1. ],\n",
      "       [12. , 39. ,  1. ],\n",
      "       [12. , 40. ,  1. ],\n",
      "       [19. , 41. ,  1. ],\n",
      "       [22. , 42. ,  1. ],\n",
      "       [22. , 43. ,  1. ],\n",
      "       [22. , 44. ,  1. ],\n",
      "       [23. , 45. ,  1. ],\n",
      "       [24. , 46. ,  1. ],\n",
      "       [24. , 47. ,  1. ],\n",
      "       [25. , 48. ,  1. ],\n",
      "       [25. , 49. ,  1. ],\n",
      "       [26. , 50. ,  1. ],\n",
      "       [26. , 51. ,  1. ],\n",
      "       [27. , 52. ,  1. ],\n",
      "       [27. , 53. ,  1. ],\n",
      "       [28. , 54. ,  1. ],\n",
      "       [28. , 55. ,  1. ]], dtype=float16), 'morgan': array([0, 0, 0, ..., 0, 0, 0], dtype=uint8), 'adj_mat_atoms': array([ 6,  6,  6,  7,  6,  7,  6,  6,  8,  7,  6,  6,  6,  7,  6,  8,  6,\n",
      "        7,  6,  8, 16,  6,  6,  6,  6,  6,  6,  6,  6,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1], dtype=uint8), 'coords': array([[-2.6437,  2.6558,  1.8087],\n",
      "       [-3.1719,  1.7205,  0.792 ],\n",
      "       [-4.325 ,  0.9662,  0.8384],\n",
      "       [-4.3651,  0.3059, -0.3525],\n",
      "       [-3.2542,  0.6579, -1.0749],\n",
      "       [-2.5077,  1.5096, -0.3968],\n",
      "       [-2.9877,  0.113 , -2.445 ],\n",
      "       [-1.8478, -0.9089, -2.3673],\n",
      "       [-1.9592, -2.0689, -2.7583],\n",
      "       [-0.6625, -0.4029, -1.8735],\n",
      "       [ 0.5412, -1.1994, -1.7706],\n",
      "       [ 0.6044, -2.0041, -0.4749],\n",
      "       [ 0.7004, -1.1392,  0.786 ],\n",
      "       [ 1.9717, -0.4177,  0.8937],\n",
      "       [ 3.1087, -1.1445,  1.2958],\n",
      "       [ 3.0134, -2.2989,  1.7181],\n",
      "       [ 4.4335, -0.4965,  1.1907],\n",
      "       [ 4.728 ,  0.4672,  0.2157],\n",
      "       [ 5.9732,  0.8373,  0.3338],\n",
      "       [ 6.4539,  1.7505, -0.4865],\n",
      "       [ 6.8928,  0.1014,  1.55  ],\n",
      "       [ 5.5197, -0.8293,  1.9976],\n",
      "       [ 5.609 , -1.817 ,  3.1096],\n",
      "       [ 1.9799,  0.9863,  0.5599],\n",
      "       [ 2.3715,  2.0323,  1.5768],\n",
      "       [ 0.9562,  1.9511,  1.1056],\n",
      "       [-4.2638, -0.4814, -3.067 ],\n",
      "       [-5.0374, -1.3481, -2.0667],\n",
      "       [-5.4363, -0.5414, -0.8336],\n",
      "       [-3.4515,  3.2528,  2.2437],\n",
      "       [-1.9173,  3.344 ,  1.3661],\n",
      "       [-2.1509,  2.1029,  2.614 ],\n",
      "       [-5.0978,  0.8699,  1.5883],\n",
      "       [-2.6367,  0.9277, -3.0916],\n",
      "       [-0.6853,  0.5273, -1.4572],\n",
      "       [ 0.5744, -1.8885, -2.6221],\n",
      "       [ 1.3953, -0.5238, -1.8672],\n",
      "       [-0.2907, -2.6331, -0.3948],\n",
      "       [ 1.4642, -2.6822, -0.5267],\n",
      "       [-0.1392, -0.4393,  0.8333],\n",
      "       [ 0.6078, -1.7915,  1.663 ],\n",
      "       [ 5.6775,  1.9278, -1.0437],\n",
      "       [ 5.5925, -2.8371,  2.7124],\n",
      "       [ 6.527 , -1.699 ,  3.6947],\n",
      "       [ 4.7657, -1.6981,  3.7978],\n",
      "       [ 2.3006,  1.1641, -0.4644],\n",
      "       [ 2.5846,  1.7168,  2.5912],\n",
      "       [ 2.9811,  2.86  ,  1.2337],\n",
      "       [ 0.5896,  2.7239,  0.4398],\n",
      "       [ 0.2208,  1.5984,  1.8178],\n",
      "       [-4.0238, -1.0711, -3.9594],\n",
      "       [-4.917 ,  0.3373, -3.3974],\n",
      "       [-4.4206, -2.2014, -1.7608],\n",
      "       [-5.9344, -1.761 , -2.5416],\n",
      "       [-5.7357, -1.2075, -0.0177],\n",
      "       [-6.2753,  0.1237, -1.0684]], dtype=float32), 'source_collection': 'zinc22', 'mod_molecule': 91396}\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.6437  2.6558  1.8087]\n",
      " [-3.1719  1.7205  0.792 ]\n",
      " [-4.325   0.9662  0.8384]\n",
      " [-4.3651  0.3059 -0.3525]\n",
      " [-3.2542  0.6579 -1.0749]\n",
      " [-2.5077  1.5096 -0.3968]\n",
      " [-2.9877  0.113  -2.445 ]\n",
      " [-1.8478 -0.9089 -2.3673]\n",
      " [-1.9592 -2.0689 -2.7583]\n",
      " [-0.6625 -0.4029 -1.8735]\n",
      " [ 0.5412 -1.1994 -1.7706]\n",
      " [ 0.6044 -2.0041 -0.4749]\n",
      " [ 0.7004 -1.1392  0.786 ]\n",
      " [ 1.9717 -0.4177  0.8937]\n",
      " [ 3.1087 -1.1445  1.2958]\n",
      " [ 3.0134 -2.2989  1.7181]\n",
      " [ 4.4335 -0.4965  1.1907]\n",
      " [ 4.728   0.4672  0.2157]\n",
      " [ 5.9732  0.8373  0.3338]\n",
      " [ 6.4539  1.7505 -0.4865]\n",
      " [ 6.8928  0.1014  1.55  ]\n",
      " [ 5.5197 -0.8293  1.9976]\n",
      " [ 5.609  -1.817   3.1096]\n",
      " [ 1.9799  0.9863  0.5599]\n",
      " [ 2.3715  2.0323  1.5768]\n",
      " [ 0.9562  1.9511  1.1056]\n",
      " [-4.2638 -0.4814 -3.067 ]\n",
      " [-5.0374 -1.3481 -2.0667]\n",
      " [-5.4363 -0.5414 -0.8336]\n",
      " [-3.4515  3.2528  2.2437]\n",
      " [-1.9173  3.344   1.3661]\n",
      " [-2.1509  2.1029  2.614 ]\n",
      " [-5.0978  0.8699  1.5883]\n",
      " [-2.6367  0.9277 -3.0916]\n",
      " [-0.6853  0.5273 -1.4572]\n",
      " [ 0.5744 -1.8885 -2.6221]\n",
      " [ 1.3953 -0.5238 -1.8672]\n",
      " [-0.2907 -2.6331 -0.3948]\n",
      " [ 1.4642 -2.6822 -0.5267]\n",
      " [-0.1392 -0.4393  0.8333]\n",
      " [ 0.6078 -1.7915  1.663 ]\n",
      " [ 5.6775  1.9278 -1.0437]\n",
      " [ 5.5925 -2.8371  2.7124]\n",
      " [ 6.527  -1.699   3.6947]\n",
      " [ 4.7657 -1.6981  3.7978]\n",
      " [ 2.3006  1.1641 -0.4644]\n",
      " [ 2.5846  1.7168  2.5912]\n",
      " [ 2.9811  2.86    1.2337]\n",
      " [ 0.5896  2.7239  0.4398]\n",
      " [ 0.2208  1.5984  1.8178]\n",
      " [-4.0238 -1.0711 -3.9594]\n",
      " [-4.917   0.3373 -3.3974]\n",
      " [-4.4206 -2.2014 -1.7608]\n",
      " [-5.9344 -1.761  -2.5416]\n",
      " [-5.7357 -1.2075 -0.0177]\n",
      " [-6.2753  0.1237 -1.0684]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(hcaii['coords'][0])\n",
    "print(type(hcaii['coords'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smiles                                                     CCC(C)(C)Br\n",
      "atoms                [6, 6, 6, 6, 6, 35, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\n",
      "coords               [[0.77919738, -0.37885212, 0.79409621], [-0.59...\n",
      "partition                                                        train\n",
      "source_collection                                             guacamol\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guacamol Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .csv file\n",
    "import pickle\n",
    "\n",
    "with open('/Users/stefanhangler/Documents/Uni/Msc_AI/3_Semester/Seminar_Practical Work/Code.nosync/COATI/examples/train_valid_test_guacamol.pkl', 'rb') as f:\n",
    "    guacamol = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "smiles                                                     CCC(C)(C)Br\n",
      "atoms                [6, 6, 6, 6, 6, 35, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\n",
      "coords               [[0.77919738, -0.37885212, 0.79409621], [-0.59...\n",
      "partition                                                        train\n",
      "source_collection                                             guacamol\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(guacamol))\n",
    "print(guacamol.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your pandas DataFrame\n",
    "df = pd.read_pickle('/Users/stefanhangler/Documents/Uni/Msc_AI/3_Semester/Seminar_Practical Work/Code.nosync/COATI/examples/train_valid_test_guacamol.pkl')  # Load your DataFrame from a pickle file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1589797/1589797 [02:43<00:00, 9718.95it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tqdm\n",
    "# Initialize an empty list to store your dictionaries\n",
    "list_of_dicts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    # Construct a dictionary for each row\n",
    "    entry = {\n",
    "        'smiles': row['smiles'],\n",
    "        'atoms': row['atoms'],\n",
    "        'coords': row['coords'],\n",
    "        'source_collection': row['source_collection'],\n",
    "        'partition': row.get('partition'),\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    list_of_dicts.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store list_of_dicts in a pickle file\n",
    "import pickle\n",
    "\n",
    "with open('/Users/stefanhangler/Documents/Uni/Msc_AI/3_Semester/Seminar_Practical Work/Code.nosync/COATI/examples/train_valid_test_guacamol_list.pkl', 'wb') as f:\n",
    "    pickle.dump(list_of_dicts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train    1271836\n",
      "test      238466\n",
      "valid      79495\n",
      "Name: partition, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/stefanhangler/Documents/Uni/Msc_AI/3_Semester/Seminar_Practical Work/Code.nosync/COATI/examples/train_valid_test_guacamol_list.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# print unique values in column 'partition' and count them\n",
    "print(df['partition'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "guacamol_df = pd.DataFrame(data)\n",
    "print(type(guacamol_df['atoms'][0]))\n",
    "\n",
    "# check if in first row the value in column partition is train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  6  6  6  6 35  1  1  1  1  1  1  1  1  1  1  1]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(df['atoms'][0])\n",
    "print(type(df['atoms'][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.77919738 -0.37885212  0.79409621]\n",
      " [-0.59915176  0.09005053  0.43215675]\n",
      " [-1.2439719  -0.79659656 -0.61070348]\n",
      " [-0.65889248  1.49995473 -0.0469612 ]\n",
      " [-1.69814093 -0.07384639  2.03462616]\n",
      " [ 2.25522228 -1.404456   -0.38616722]\n",
      " [ 2.57259291  0.32551001 -0.17056892]\n",
      " [ 1.2720485  -0.27115557 -1.32946089]\n",
      " [ 0.661645   -1.41826167  1.20853113]\n",
      " [ 1.204467    0.21590541  1.62506238]\n",
      " [-1.05566783 -0.36153166 -1.62369487]\n",
      " [-2.33335852 -0.85974912 -0.49246425]\n",
      " [-0.75625327 -1.79781899 -0.56980021]\n",
      " [-1.71496358  1.84056761  0.02737312]\n",
      " [-0.35748139  1.60001995 -1.12210047]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(df['coords'][0])\n",
    "print(type(df['coords'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  6  6  6  6 35  1  1  1  1  1  1  1  1  1  1  1]\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 0.77919738 -0.37885212  0.79409621]\n",
      " [-0.59915176  0.09005053  0.43215675]\n",
      " [-1.2439719  -0.79659656 -0.61070348]\n",
      " [-0.65889248  1.49995473 -0.0469612 ]\n",
      " [-1.69814093 -0.07384639  2.03462616]\n",
      " [ 2.25522228 -1.404456   -0.38616722]\n",
      " [ 2.57259291  0.32551001 -0.17056892]\n",
      " [ 1.2720485  -0.27115557 -1.32946089]\n",
      " [ 0.661645   -1.41826167  1.20853113]\n",
      " [ 1.204467    0.21590541  1.62506238]\n",
      " [-1.05566783 -0.36153166 -1.62369487]\n",
      " [-2.33335852 -0.85974912 -0.49246425]\n",
      " [-0.75625327 -1.79781899 -0.56980021]\n",
      " [-1.71496358  1.84056761  0.02737312]\n",
      " [-0.35748139  1.60001995 -1.12210047]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# Function to convert string representation of space-separated numbers to numpy.ndarray\n",
    "def str_to_ndarray(s):\n",
    "    # Remove square brackets and split the string by spaces\n",
    "    s = s.strip('[]')\n",
    "    return np.array([int(x) for x in s.split()])\n",
    "\n",
    "# Function to convert string representation of lists of lists with floats\n",
    "def str_to_ndarray_2d(s):\n",
    "    # Use regex to find all groups of floats\n",
    "    s = s.strip('[]')\n",
    "    groups = re.findall(r'\\[([^\\]]+)\\]', s)\n",
    "    cleaned_groups = [group.replace('[', '').replace(']', '') for group in groups]\n",
    "    return np.array([list(map(float, group.split())) for group in cleaned_groups])\n",
    "\n",
    "\n",
    "# Apply the function to the 'atoms' column\n",
    "#df['atoms'] = df['atoms'].apply(str_to_ndarray)\n",
    "\n",
    "# Apply the function to the 'coords' column\n",
    "df['coords'] = df['coords'].apply(str_to_ndarray_2d)\n",
    "\n",
    "# Verify the conversion\n",
    "print(df['atoms'][0])\n",
    "print(type(df['atoms'][0]))\n",
    "\n",
    "print(df['coords'][0])\n",
    "print(type(df['coords'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe df as .pkl file and csv file\n",
    "df.to_pickle('/Users/stefanhangler/Documents/Uni/Msc_AI/3_Semester/Seminar_Practical Work/Code.nosync/COATI/examples/train_valid_test_guacamol.pkl')\n",
    "df.to_csv('/Users/stefanhangler/Documents/Uni/Msc_AI/3_Semester/Seminar_Practical Work/Code.nosync/COATI/examples/train_valid_test_guacamol.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_links(file_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Load dataset links from a text file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the text file containing dataset links.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dataset URLs.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        links = file.read().splitlines()\n",
    "    return links\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# def download_from_s3(url: str, local_dir: str):\n",
    "#     \"\"\"\n",
    "#     Download a file from an S3 bucket URL to a local directory.\n",
    "\n",
    "#     Args:\n",
    "#         url (str): The S3 URL of the file.\n",
    "#         local_dir (str): The local directory to save the file.\n",
    "#     \"\"\"\n",
    "#     bucket_name = url.split('/')[2]\n",
    "#     object_key = '/'.join(url.split('/')[3:])\n",
    "#     local_path = os.path.join(local_dir, object_key.split('/')[-1])\n",
    "    \n",
    "#     s3 = boto3.client('s3')\n",
    "#     if not os.path.exists(local_dir):\n",
    "#         os.makedirs(local_dir, exist_ok=True)\n",
    "#     s3.download_file(Bucket=bucket_name, Key=object_key, Filename=local_path)\n",
    "#     print(f\"Downloaded {object_key} to {local_path}\")\n",
    "#     return local_path\n",
    "\n",
    "def load_pickle_file(file_path: str):\n",
    "    \"\"\"\n",
    "    Load a pickle file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the pickle file.\n",
    "\n",
    "    Returns:\n",
    "        Any: The content loaded from the pickle file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing link: s3://terray-public/datasets/ames.pkl\n"
     ]
    },
    {
     "ename": "EndpointConnectionError",
     "evalue": "Could not connect to the endpoint URL: \"https://terray-public.s3.Austria.amazonaws.com/datasets/ames.pkl\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/connection.py:159\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/util/connection.py:61\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     59\u001b[0m family \u001b[38;5;241m=\u001b[39m allowed_gai_family()\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     62\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/socket.py:954\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    953\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    955\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/httpsession.py:253\u001b[0m, in \u001b[0;36mURLLib3Session.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    252\u001b[0m request_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_target(request\u001b[38;5;241m.\u001b[39murl, proxy_url)\n\u001b[0;32m--> 253\u001b[0m urllib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m http_response \u001b[38;5;241m=\u001b[39m botocore\u001b[38;5;241m.\u001b[39mawsrequest\u001b[38;5;241m.\u001b[39mAWSResponse(\n\u001b[1;32m    266\u001b[0m     request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m    267\u001b[0m     urllib_response\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    268\u001b[0m     urllib_response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    269\u001b[0m     urllib_response,\n\u001b[1;32m    270\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/connectionpool.py:726\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    724\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 726\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/util/retry.py:386\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m error:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# Disabled, indicate to re-raise the error.\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/packages/six.py:735\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 735\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/connectionpool.py:670\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 670\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/connectionpool.py:381\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/connectionpool.py:978\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/connection.py:309\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/urllib3/connection.py:171\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <botocore.awsrequest.AWSHTTPSConnection object at 0x7f9112adbc40>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEndpointConnectionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m dataset_links:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing link:\u001b[39m\u001b[38;5;124m\"\u001b[39m, link)\n\u001b[0;32m----> 7\u001b[0m     local_file_path \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_from_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m load_pickle_file(local_file_path)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded dataset with keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m, in \u001b[0;36mdownload_from_s3\u001b[0;34m(url, local_dir)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_dir):\n\u001b[1;32m     33\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(local_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 34\u001b[0m \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m local_path\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/boto3/s3/inject.py:170\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/boto3/s3/transfer.py:307\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    304\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[1;32m    305\u001b[0m     bucket, key, filename, extra_args, subscribers)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/s3transfer/futures.py:106\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;66;03m# out of this and propogate the exception.\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/s3transfer/futures.py:265\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/s3transfer/tasks.py:255\u001b[0m, in \u001b[0;36mSubmissionTask._main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator\u001b[38;5;241m.\u001b[39mset_status_to_running()\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# Call the submit method to start submitting tasks to execute the\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# transfer.\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_submit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# If there was an exception raised during the submission of task\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# there is a chance that the final task that signals if a transfer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# Set the exception, that caused the process to fail.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_and_set_exception(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/s3transfer/download.py:342\u001b[0m, in \u001b[0;36mDownloadSubmissionTask._submit\u001b[0;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m:param client: The client associated with the transfer manager\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    downloading streams\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transfer_future\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39msize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# If a size was not provided figure out the size for the\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# user.\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtransfer_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_args\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     transfer_future\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mprovide_transfer_size(\n\u001b[1;32m    348\u001b[0m         response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContentLength\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    350\u001b[0m download_output_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_download_output_manager_cls(\n\u001b[1;32m    351\u001b[0m     transfer_future, osutil)(osutil, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator,\n\u001b[1;32m    352\u001b[0m                              io_executor)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/client.py:357\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m py_operation_name)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/client.py:647\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    645\u001b[0m     http, parsed_response \u001b[38;5;241m=\u001b[39m event_response\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 647\u001b[0m     http, parsed_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter-call.\u001b[39m\u001b[38;5;132;01m{service_id}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{operation_name}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    652\u001b[0m         service_id\u001b[38;5;241m=\u001b[39mservice_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    655\u001b[0m     model\u001b[38;5;241m=\u001b[39moperation_model, context\u001b[38;5;241m=\u001b[39mrequest_context\n\u001b[1;32m    656\u001b[0m )\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/client.py:667\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_endpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m    670\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter-call-error.\u001b[39m\u001b[38;5;132;01m{service_id}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{operation_name}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    671\u001b[0m                 service_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_model\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;241m.\u001b[39mhyphenize(),\n\u001b[1;32m    672\u001b[0m                 operation_name\u001b[38;5;241m=\u001b[39moperation_model\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    673\u001b[0m             exception\u001b[38;5;241m=\u001b[39me, context\u001b[38;5;241m=\u001b[39mrequest_context\n\u001b[1;32m    674\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/endpoint.py:102\u001b[0m, in \u001b[0;36mEndpoint.make_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict):\n\u001b[1;32m    100\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking request for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with params: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m                  operation_model, request_dict)\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/endpoint.py:136\u001b[0m, in \u001b[0;36mEndpoint._send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    133\u001b[0m context \u001b[38;5;241m=\u001b[39m request_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    134\u001b[0m success_response, exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_response(\n\u001b[1;32m    135\u001b[0m     request, operation_model, context)\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_needs_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattempts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msuccess_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    138\u001b[0m     attempts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# If there is a stream associated with the request, we need\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# to reset it before attempting to send the request again.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# This will ensure that we resend the entire contents of the\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# body.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/endpoint.py:228\u001b[0m, in \u001b[0;36mEndpoint._needs_retry\u001b[0;34m(self, attempts, operation_model, request_dict, response, caught_exception)\u001b[0m\n\u001b[1;32m    224\u001b[0m service_id \u001b[38;5;241m=\u001b[39m operation_model\u001b[38;5;241m.\u001b[39mservice_model\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;241m.\u001b[39mhyphenize()\n\u001b[1;32m    225\u001b[0m event_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneeds-retry.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    226\u001b[0m     service_id,\n\u001b[1;32m    227\u001b[0m     operation_model\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 228\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_emitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattempts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattempts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaught_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaught_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m handler_response \u001b[38;5;241m=\u001b[39m first_non_none_response(responses)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/hooks.py:356\u001b[0m, in \u001b[0;36mEventAliaser.emit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21memit\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    355\u001b[0m     aliased_event_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alias_event_name(event_name)\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_emitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43maliased_event_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/hooks.py:228\u001b[0m, in \u001b[0;36mHierarchicalEmitter.emit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21memit\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    Emit an event by name with arguments passed as keyword args.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m             handlers.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_emit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/hooks.py:211\u001b[0m, in \u001b[0;36mHierarchicalEmitter._emit\u001b[0;34m(self, event_name, kwargs, stop_on_response)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers_to_call:\n\u001b[1;32m    210\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling handler \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, event_name, handler)\n\u001b[0;32m--> 211\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend((handler, response))\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_on_response \u001b[38;5;129;01mand\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/retryhandler.py:183\u001b[0m, in \u001b[0;36mRetryHandler.__call__\u001b[0;34m(self, attempts, response, caught_exception, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attempts, response, caught_exception, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Handler for a retry.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    Intended to be hooked up to an event handler (hence the **kwargs),\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    this will process retries appropriately.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattempts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaught_exception\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    184\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action(attempts\u001b[38;5;241m=\u001b[39mattempts)\n\u001b[1;32m    185\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry needed, action of: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/retryhandler.py:250\u001b[0m, in \u001b[0;36mMaxAttemptsDecorator.__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attempt_number, response, caught_exception):\n\u001b[0;32m--> 250\u001b[0m     should_retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattempt_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mcaught_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_retry:\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m attempt_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_attempts:\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;66;03m# explicitly set MaxAttemptsReached\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/retryhandler.py:277\u001b[0m, in \u001b[0;36mMaxAttemptsDecorator._should_retry\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# If we've exceeded the max attempts we just let the exception\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# propogate if one has occurred.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattempt_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaught_exception\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/retryhandler.py:316\u001b[0m, in \u001b[0;36mMultiChecker.__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attempt_number, response, caught_exception):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m checker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkers:\n\u001b[0;32m--> 316\u001b[0m         checker_response \u001b[38;5;241m=\u001b[39m \u001b[43mchecker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattempt_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mcaught_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m checker_response:\n\u001b[1;32m    319\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m checker_response\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/retryhandler.py:222\u001b[0m, in \u001b[0;36mBaseChecker.__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(attempt_number, response)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m caught_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_caught_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattempt_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaught_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoth response and caught_exception are None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/retryhandler.py:359\u001b[0m, in \u001b[0;36mExceptionRaiser._check_caught_exception\u001b[0;34m(self, attempt_number, caught_exception)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_caught_exception\u001b[39m(\u001b[38;5;28mself\u001b[39m, attempt_number, caught_exception):\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;66;03m# This is implementation specific, but this class is useful by\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# coordinating with the MaxAttemptsDecorator.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# the MaxAttemptsDecorator is not interested in retrying the exception\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# then this exception just propogates out past the retry code.\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m caught_exception\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/endpoint.py:200\u001b[0m, in \u001b[0;36mEndpoint._do_get_response\u001b[0;34m(self, request, operation_model)\u001b[0m\n\u001b[1;32m    198\u001b[0m     http_response \u001b[38;5;241m=\u001b[39m first_non_none_response(responses)\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m http_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         http_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/endpoint.py:244\u001b[0m, in \u001b[0;36mEndpoint._send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_send\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/coatiEnv/lib/python3.9/site-packages/botocore/httpsession.py:282\u001b[0m, in \u001b[0;36mURLLib3Session.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(endpoint_url\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39murl, error\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (NewConnectionError, socket\u001b[38;5;241m.\u001b[39mgaierror) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EndpointConnectionError(endpoint_url\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39murl, error\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProxyError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProxyConnectionError(proxy_url\u001b[38;5;241m=\u001b[39mproxy_url, error\u001b[38;5;241m=\u001b[39me)\n",
      "\u001b[0;31mEndpointConnectionError\u001b[0m: Could not connect to the endpoint URL: \"https://terray-public.s3.Austria.amazonaws.com/datasets/ames.pkl\""
     ]
    }
   ],
   "source": [
    "links_path = 'admet_datasets.txt'\n",
    "dataset_links = load_dataset_links(links_path)\n",
    "local_dir = './datasets'\n",
    "\n",
    "for link in dataset_links:\n",
    "    print(\"Processing link:\", link)\n",
    "    local_file_path = download_from_s3(link, local_dir)\n",
    "    dataset = load_pickle_file(local_file_path)\n",
    "    print(f\"Loaded dataset with keys: {list(dataset[0].keys()) if len(dataset) > 0 else 'Empty dataset'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>atoms</th>\n",
       "      <th>Drug</th>\n",
       "      <th>partition</th>\n",
       "      <th>Y</th>\n",
       "      <th>smiles</th>\n",
       "      <th>coords</th>\n",
       "      <th>Barlow Venti (Text)</th>\n",
       "      <th>...</th>\n",
       "      <th>Barlow Closed FP (Point)</th>\n",
       "      <th>RDKit 2D</th>\n",
       "      <th>RDKit FP</th>\n",
       "      <th>ECFP6 2048</th>\n",
       "      <th>CDDD</th>\n",
       "      <th>ChemBERTa MTR</th>\n",
       "      <th>MegaMolBART</th>\n",
       "      <th>ChemGPT</th>\n",
       "      <th>CLAMP</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>clintox</td>\n",
       "      <td>Drug 663</td>\n",
       "      <td>[6, 6, 6, 16, 6, 7, 6, 8, 8, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>CC(C)(S)[C@@H]([NH3+])C(=O)[O-]</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>CC(C)(S)[C@@H]([NH3+])C(=O)[O-]</td>\n",
       "      <td>[[-1.1587, 1.501, 0.4467], [-0.5729, 0.086, 0....</td>\n",
       "      <td>[-0.48596588, -0.40367287, -0.32968014, -0.040...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.034439653, 0.34682173, 0.5232295, 0.339287...</td>\n",
       "      <td>[1.0, 0.9952556386838793, 0.003338733333477606...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-0.9194064, 0.3526249, -0.44385064, -0.948228...</td>\n",
       "      <td>[-0.3597712218761444, 0.15387509763240814, -0....</td>\n",
       "      <td>[-0.17382812, 0.63671875, 0.13928223, -0.65039...</td>\n",
       "      <td>[1.6211647987365723, 0.35510388016700745, 0.39...</td>\n",
       "      <td>[2.9962983, 0.10253586, -0.07844463, -0.073737...</td>\n",
       "      <td>TDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>clintox</td>\n",
       "      <td>Drug 275</td>\n",
       "      <td>[7, 6, 7, 6, 8, 6, 6, 6, 6, 6, 6, 6, 8, 1, 1, ...</td>\n",
       "      <td>NC1=[NH+]C(=O)C(c2ccccc2)O1</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>NC1=[NH+]C(=O)C(c2ccccc2)O1</td>\n",
       "      <td>[[3.4802, 1.2624, 0.2219], [2.5354, 0.4995, -0...</td>\n",
       "      <td>[0.2941416, 0.18029086, -0.22861026, -0.049696...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.037776455, 0.2113951, 1.1339982, 0.2314647...</td>\n",
       "      <td>[1.0, 0.8736604457896888, 0.037759519196055025...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.80000734, 0.71778387, 0.64834, -0.3823671, ...</td>\n",
       "      <td>[-0.01589236594736576, -0.07616246491670609, -...</td>\n",
       "      <td>[-0.013938904, 0.041931152, 0.77197266, -0.155...</td>\n",
       "      <td>[2.141200065612793, 1.1489925384521484, 0.2110...</td>\n",
       "      <td>[3.1824074, 0.035340086, 0.14812317, 0.1164644...</td>\n",
       "      <td>TDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>clintox</td>\n",
       "      <td>Drug 396</td>\n",
       "      <td>[6, 6, 6, 6, 6, 7, 6, 8, 6, 6, 7, 6, 8, 6, 7, ...</td>\n",
       "      <td>CC(C)C[C@@H](NC(=O)[C@H](C)NC(=O)CNC(=O)[C@@H]...</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>CC(C)C[C@@H](NC(=O)[C@H](C)NC(=O)CNC(=O)[C@@H]...</td>\n",
       "      <td>[[-6.1262, -3.7166, 7.069], [-6.9619, -2.4409,...</td>\n",
       "      <td>[-0.12584504, -0.21312052, -0.15873043, -0.420...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.4703792, 0.124379374, 0.16749996, 0.7778032...</td>\n",
       "      <td>[1.0, 0.005977392609663165, 0.9999999999997586...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-0.5920336, -0.28254712, -0.18214382, 1.26347...</td>\n",
       "      <td>[0.07713872939348221, -0.0604865662753582, -0....</td>\n",
       "      <td>[0.23083496, -0.30786133, -0.095703125, -0.866...</td>\n",
       "      <td>[1.766483187675476, 1.7701389789581299, -0.522...</td>\n",
       "      <td>[1.8480616, 0.13712236, 0.101326905, 0.0477170...</td>\n",
       "      <td>TDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>clintox</td>\n",
       "      <td>Drug 219</td>\n",
       "      <td>[7, 6, 6, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 8, 7, ...</td>\n",
       "      <td>Nc1cccc2c1CN(C1CCC(=O)NC1=O)C2=O</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>Nc1cccc2c1CN(C1CCC(=O)NC1=O)C2=O</td>\n",
       "      <td>[[3.1444, 0.2364, -2.4085], [3.1163, -0.0045, ...</td>\n",
       "      <td>[-0.17993519, -0.12503093, -0.10035531, -0.714...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.6833182, 0.026306301, 0.10959904, -0.40253...</td>\n",
       "      <td>[1.0, 0.679323244027271, 0.16051684104770916, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.495663, 0.04323706, 0.7806182, -0.07695059,...</td>\n",
       "      <td>[-0.16631020605564117, -0.0597807802259922, -0...</td>\n",
       "      <td>[-0.32470703, -0.008514404, 0.6621094, 0.00224...</td>\n",
       "      <td>[1.6884082555770874, 1.4459658861160278, 0.012...</td>\n",
       "      <td>[2.1314294, -0.08267841, 0.08518608, -0.048729...</td>\n",
       "      <td>TDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>clintox</td>\n",
       "      <td>Drug 923</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>Cc1c(C)c2c(c(C)c1O)CCC(C)(COc1ccc(CC3SC(=O)[N-...</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>Cc1c(C)c2c(c(C)c1O)CCC(C)(COc1ccc(CC3SC(=O)[N-...</td>\n",
       "      <td>[[-6.5206, 0.6231, 2.6371], [-5.5766, 0.2606, ...</td>\n",
       "      <td>[-0.09498369, 0.3513912, -0.19573663, -0.27671...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.2950976, 1.0571643, -0.057204343, 0.200984...</td>\n",
       "      <td>[1.0, 0.150942407522209, 0.6028500013673688, 0...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.7904057, 0.5615183, 0.9352038, -0.58156925,...</td>\n",
       "      <td>[-0.2895241677761078, 0.3468022048473358, -0.1...</td>\n",
       "      <td>[-0.2680664, 0.033111572, 0.03604126, -0.43627...</td>\n",
       "      <td>[1.7198771238327026, 1.8177869319915771, -0.04...</td>\n",
       "      <td>[1.5690616, 0.048072208, 0.08898854, 0.0396719...</td>\n",
       "      <td>TDC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  dataset   Drug_ID  \\\n",
       "0       0  clintox  Drug 663   \n",
       "1       0  clintox  Drug 275   \n",
       "2       0  clintox  Drug 396   \n",
       "3       0  clintox  Drug 219   \n",
       "4       0  clintox  Drug 923   \n",
       "\n",
       "                                               atoms  \\\n",
       "0  [6, 6, 6, 16, 6, 7, 6, 8, 8, 1, 1, 1, 1, 1, 1,...   \n",
       "1  [7, 6, 7, 6, 8, 6, 6, 6, 6, 6, 6, 6, 8, 1, 1, ...   \n",
       "2  [6, 6, 6, 6, 6, 7, 6, 8, 6, 6, 7, 6, 8, 6, 7, ...   \n",
       "3  [7, 6, 6, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 8, 7, ...   \n",
       "4  [6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, ...   \n",
       "\n",
       "                                                Drug partition  Y  \\\n",
       "0                    CC(C)(S)[C@@H]([NH3+])C(=O)[O-]      test  0   \n",
       "1                        NC1=[NH+]C(=O)C(c2ccccc2)O1      test  0   \n",
       "2  CC(C)C[C@@H](NC(=O)[C@H](C)NC(=O)CNC(=O)[C@@H]...      test  0   \n",
       "3                   Nc1cccc2c1CN(C1CCC(=O)NC1=O)C2=O      test  0   \n",
       "4  Cc1c(C)c2c(c(C)c1O)CCC(C)(COc1ccc(CC3SC(=O)[N-...      test  0   \n",
       "\n",
       "                                              smiles  \\\n",
       "0                    CC(C)(S)[C@@H]([NH3+])C(=O)[O-]   \n",
       "1                        NC1=[NH+]C(=O)C(c2ccccc2)O1   \n",
       "2  CC(C)C[C@@H](NC(=O)[C@H](C)NC(=O)CNC(=O)[C@@H]...   \n",
       "3                   Nc1cccc2c1CN(C1CCC(=O)NC1=O)C2=O   \n",
       "4  Cc1c(C)c2c(c(C)c1O)CCC(C)(COc1ccc(CC3SC(=O)[N-...   \n",
       "\n",
       "                                              coords  \\\n",
       "0  [[-1.1587, 1.501, 0.4467], [-0.5729, 0.086, 0....   \n",
       "1  [[3.4802, 1.2624, 0.2219], [2.5354, 0.4995, -0...   \n",
       "2  [[-6.1262, -3.7166, 7.069], [-6.9619, -2.4409,...   \n",
       "3  [[3.1444, 0.2364, -2.4085], [3.1163, -0.0045, ...   \n",
       "4  [[-6.5206, 0.6231, 2.6371], [-5.5766, 0.2606, ...   \n",
       "\n",
       "                                 Barlow Venti (Text)  ...  \\\n",
       "0  [-0.48596588, -0.40367287, -0.32968014, -0.040...  ...   \n",
       "1  [0.2941416, 0.18029086, -0.22861026, -0.049696...  ...   \n",
       "2  [-0.12584504, -0.21312052, -0.15873043, -0.420...  ...   \n",
       "3  [-0.17993519, -0.12503093, -0.10035531, -0.714...  ...   \n",
       "4  [-0.09498369, 0.3513912, -0.19573663, -0.27671...  ...   \n",
       "\n",
       "                            Barlow Closed FP (Point)  \\\n",
       "0  [-0.034439653, 0.34682173, 0.5232295, 0.339287...   \n",
       "1  [-0.037776455, 0.2113951, 1.1339982, 0.2314647...   \n",
       "2  [0.4703792, 0.124379374, 0.16749996, 0.7778032...   \n",
       "3  [-0.6833182, 0.026306301, 0.10959904, -0.40253...   \n",
       "4  [-0.2950976, 1.0571643, -0.057204343, 0.200984...   \n",
       "\n",
       "                                            RDKit 2D  \\\n",
       "0  [1.0, 0.9952556386838793, 0.003338733333477606...   \n",
       "1  [1.0, 0.8736604457896888, 0.037759519196055025...   \n",
       "2  [1.0, 0.005977392609663165, 0.9999999999997586...   \n",
       "3  [1.0, 0.679323244027271, 0.16051684104770916, ...   \n",
       "4  [1.0, 0.150942407522209, 0.6028500013673688, 0...   \n",
       "\n",
       "                                            RDKit FP  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, ...   \n",
       "3  [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...   \n",
       "\n",
       "                                          ECFP6 2048  \\\n",
       "0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                CDDD  \\\n",
       "0  [-0.9194064, 0.3526249, -0.44385064, -0.948228...   \n",
       "1  [0.80000734, 0.71778387, 0.64834, -0.3823671, ...   \n",
       "2  [-0.5920336, -0.28254712, -0.18214382, 1.26347...   \n",
       "3  [0.495663, 0.04323706, 0.7806182, -0.07695059,...   \n",
       "4  [0.7904057, 0.5615183, 0.9352038, -0.58156925,...   \n",
       "\n",
       "                                       ChemBERTa MTR  \\\n",
       "0  [-0.3597712218761444, 0.15387509763240814, -0....   \n",
       "1  [-0.01589236594736576, -0.07616246491670609, -...   \n",
       "2  [0.07713872939348221, -0.0604865662753582, -0....   \n",
       "3  [-0.16631020605564117, -0.0597807802259922, -0...   \n",
       "4  [-0.2895241677761078, 0.3468022048473358, -0.1...   \n",
       "\n",
       "                                         MegaMolBART  \\\n",
       "0  [-0.17382812, 0.63671875, 0.13928223, -0.65039...   \n",
       "1  [-0.013938904, 0.041931152, 0.77197266, -0.155...   \n",
       "2  [0.23083496, -0.30786133, -0.095703125, -0.866...   \n",
       "3  [-0.32470703, -0.008514404, 0.6621094, 0.00224...   \n",
       "4  [-0.2680664, 0.033111572, 0.03604126, -0.43627...   \n",
       "\n",
       "                                             ChemGPT  \\\n",
       "0  [1.6211647987365723, 0.35510388016700745, 0.39...   \n",
       "1  [2.141200065612793, 1.1489925384521484, 0.2110...   \n",
       "2  [1.766483187675476, 1.7701389789581299, -0.522...   \n",
       "3  [1.6884082555770874, 1.4459658861160278, 0.012...   \n",
       "4  [1.7198771238327026, 1.8177869319915771, -0.04...   \n",
       "\n",
       "                                               CLAMP source  \n",
       "0  [2.9962983, 0.10253586, -0.07844463, -0.073737...    TDC  \n",
       "1  [3.1824074, 0.035340086, 0.14812317, 0.1164644...    TDC  \n",
       "2  [1.8480616, 0.13712236, 0.101326905, 0.0477170...    TDC  \n",
       "3  [2.1314294, -0.08267841, 0.08518608, -0.048729...    TDC  \n",
       "4  [1.5690616, 0.048072208, 0.08898854, 0.0396719...    TDC  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#from coati.common.s3 import download_from_s3\n",
    "\n",
    "#download_from_s3(\"s3://terray-public/datasets/delaney.pkl\")\n",
    "\n",
    "# datasets are available as pickle files (list of dictionaries)\n",
    "with open(\"./datasets/clintox.pkl\", \"rb\") as f:\n",
    "    delaney = pickle.load(f)\n",
    "\n",
    "# to pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(delaney)\n",
    "df.head()\n",
    "\n",
    "# print unique value in df for column 'target'\n",
    "#df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset ames.pkl\n",
      "7278\n",
      "Loaded dataset bace_regression.pkl\n",
      "1513\n",
      "Loaded dataset cyp3a4_veith.pkl\n",
      "12328\n",
      "Loaded dataset bace_classification.pkl\n",
      "1513\n",
      "Loaded dataset chembl_canonical_smiles.pkl\n",
      "2177805\n",
      "Loaded dataset half_life_obach.pkl\n",
      "667\n",
      "Loaded dataset pgp_broccatelli.pkl\n",
      "1218\n",
      "Loaded dataset bioavailability_ma.pkl\n",
      "640\n",
      "Loaded dataset caco2_wang.pkl\n",
      "910\n",
      "Loaded dataset clintox.pkl\n",
      "1478\n",
      "Loaded dataset herg_karim.pkl\n",
      "13445\n",
      "Loaded dataset clearance_microsome_az.pkl\n",
      "1102\n",
      "Loaded dataset clearance_hepatocyte_az.pkl\n",
      "1213\n",
      "Loaded dataset hiv.pkl\n",
      "41127\n",
      "Loaded dataset dili.pkl\n",
      "475\n",
      "Loaded dataset ppbr_az.pkl\n",
      "2790\n",
      "Loaded dataset vdss_lombardo.pkl\n",
      "1130\n",
      "Loaded dataset hia_hou.pkl\n",
      "578\n",
      "Loaded dataset cyp2c9_veith.pkl\n",
      "12092\n",
      "Loaded dataset ld50_zhu.pkl\n",
      "7385\n",
      "Loaded dataset herg.pkl\n",
      "655\n",
      "Loaded dataset delaney.pkl\n",
      "1128\n"
     ]
    }
   ],
   "source": [
    "# iterate over all datasets in './datasets' directory\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "for file in os.listdir('./datasets'):\n",
    "    if file.endswith('.pkl'):\n",
    "        with open(f'./datasets/{file}', 'rb') as f:\n",
    "            dataset = pickle.load(f)\n",
    "            print(f\"Loaded dataset {file}\")\n",
    "            # check if dataset has columns\n",
    "            print(len(dataset))\n",
    "            # try:\n",
    "            #     if 'target' in dataset[0].keys():\n",
    "            #         print(f\"unique values in target column: {pd.DataFrame(dataset)['target'].unique()}\")\n",
    "            #     # elif dataset has columns\n",
    "            #     elif len(dataset) > 0:\n",
    "            #         print(\"columns: \", list(dataset[0].keys()))\n",
    "            # except:\n",
    "            #     # dataset to dataframe\n",
    "            #     df = pd.DataFrame(dataset)\n",
    "            #     print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(delaney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ames.pkl already exists\n",
      "bace_classification.pkl already exists\n",
      "bace_regression.pkl already exists\n",
      "bioavailability_ma.pkl already exists\n",
      "caco2_wang.pkl already exists\n",
      "chembl_canonical_smiles.pkl already exists\n",
      "clearance_hepatocyte_az.pkl already exists\n",
      "clearance_microsome_az.pkl already exists\n",
      "clintox.pkl already exists\n",
      "delaney.pkl already exists\n",
      "dili.pkl already exists\n",
      "half_life_obach.pkl already exists\n",
      "herg.pkl already exists\n",
      "Downloading datasets/herg_inhib.pkl from terray-public\n",
      "Failed to download herg_inhib.pkl: Could not connect to the endpoint URL: \"https://terray-public.s3.us-west-2.amazonaws.com/datasets/herg_inhib.pkl\"\n",
      "Downloading datasets/herg_karim.pkl from terray-public\n",
      "File downloaded successfully to ./datasets/herg_karim.pkl\n",
      "herg_karim.pkl:\n",
      " dict_keys(['raw_smiles', 'smiles', 'partition', 'dataset', 'atoms', 'coords', 'target', 'Barlow Venti (Text)', 'Barlow Venti (Point)', 'Grande Open (Text)', 'Grande Open (Point)', 'Tall Closed (Text)', 'Tall Closed (Point)', 'Barlow Closed (Text)', 'Barlow Closed (Point)', 'Grande Closed (Text)', 'Grande Closed (Point)', 'Barlow Closed FP (Text)', 'Barlow Closed FP (Point)', 'RDKit 2D', 'RDKit FP', 'ECFP6 2048', 'CDDD', 'ChemBERTa MTR', 'MegaMolBART', 'ChemGPT', 'CLAMP', 'source'])\n",
      "Downloading datasets/hia_hou.pkl from terray-public\n",
      "File downloaded successfully to ./datasets/hia_hou.pkl\n",
      "hia_hou.pkl:\n",
      " dict_keys(['raw_smiles', 'smiles', 'partition', 'dataset', 'atoms', 'coords', 'target', 'Barlow Venti (Text)', 'Barlow Venti (Point)', 'Grande Open (Text)', 'Grande Open (Point)', 'Tall Closed (Text)', 'Tall Closed (Point)', 'Barlow Closed (Text)', 'Barlow Closed (Point)', 'Grande Closed (Text)', 'Grande Closed (Point)', 'Barlow Closed FP (Text)', 'Barlow Closed FP (Point)', 'RDKit 2D', 'RDKit FP', 'ECFP6 2048', 'CDDD', 'ChemBERTa MTR', 'MegaMolBART', 'ChemGPT', 'CLAMP', 'source'])\n",
      "Downloading datasets/hiv.pkl from terray-public\n",
      "File downloaded successfully to ./datasets/hiv.pkl\n",
      "hiv.pkl:\n",
      " dict_keys(['raw_smiles', 'smiles', 'partition', 'dataset', 'atoms', 'coords', 'target', 'Barlow Venti (Text)', 'Barlow Venti (Point)', 'Grande Open (Text)', 'Grande Open (Point)', 'Tall Closed (Text)', 'Tall Closed (Point)', 'Barlow Closed (Text)', 'Barlow Closed (Point)', 'Grande Closed (Text)', 'Grande Closed (Point)', 'Barlow Closed FP (Text)', 'Barlow Closed FP (Point)', 'RDKit 2D', 'RDKit FP', 'ECFP6 2048', 'CDDD', 'ChemBERTa MTR', 'MegaMolBART', 'ChemGPT', 'CLAMP', 'source'])\n",
      "Downloading datasets/ld50_zhu.pkl from terray-public\n",
      "File downloaded successfully to ./datasets/ld50_zhu.pkl\n",
      "ld50_zhu.pkl:\n",
      " dict_keys(['raw_smiles', 'smiles', 'partition', 'dataset', 'atoms', 'coords', 'target', 'Barlow Venti (Text)', 'Barlow Venti (Point)', 'Grande Open (Text)', 'Grande Open (Point)', 'Tall Closed (Text)', 'Tall Closed (Point)', 'Barlow Closed (Text)', 'Barlow Closed (Point)', 'Grande Closed (Text)', 'Grande Closed (Point)', 'Barlow Closed FP (Text)', 'Barlow Closed FP (Point)', 'RDKit 2D', 'RDKit FP', 'ECFP6 2048', 'CDDD', 'ChemBERTa MTR', 'MegaMolBART', 'ChemGPT', 'CLAMP', 'source'])\n",
      "Downloading datasets/lipophilicity_astrazeneca.pkl from terray-public\n",
      "Failed to download lipophilicity_astrazeneca.pkl: Could not connect to the endpoint URL: \"https://terray-public.s3.us-west-2.amazonaws.com/datasets/lipophilicity_astrazeneca.pkl\"\n",
      "Downloading datasets/pampa_ncats.pkl from terray-public\n",
      "Failed to download pampa_ncats.pkl: Could not connect to the endpoint URL: \"https://terray-public.s3.us-west-2.amazonaws.com/datasets/pampa_ncats.pkl\"\n",
      "Downloading datasets/pgp_broccatelli.pkl from terray-public\n",
      "File downloaded successfully to ./datasets/pgp_broccatelli.pkl\n",
      "pgp_broccatelli.pkl:\n",
      " dict_keys(['raw_smiles', 'smiles', 'partition', 'dataset', 'atoms', 'coords', 'target', 'Barlow Venti (Text)', 'Barlow Venti (Point)', 'Grande Open (Text)', 'Grande Open (Point)', 'Tall Closed (Text)', 'Tall Closed (Point)', 'Barlow Closed (Text)', 'Barlow Closed (Point)', 'Grande Closed (Text)', 'Grande Closed (Point)', 'Barlow Closed FP (Text)', 'Barlow Closed FP (Point)', 'RDKit 2D', 'RDKit FP', 'ECFP6 2048', 'CDDD', 'ChemBERTa MTR', 'MegaMolBART', 'ChemGPT', 'CLAMP', 'source'])\n",
      "Downloading datasets/ppbr_az.pkl from terray-public\n",
      "File downloaded successfully to ./datasets/ppbr_az.pkl\n",
      "ppbr_az.pkl:\n",
      " dict_keys(['raw_smiles', 'smiles', 'partition', 'dataset', 'atoms', 'coords', 'target', 'Barlow Venti (Text)', 'Barlow Venti (Point)', 'Grande Open (Text)', 'Grande Open (Point)', 'Tall Closed (Text)', 'Tall Closed (Point)', 'Barlow Closed (Text)', 'Barlow Closed (Point)', 'Grande Closed (Text)', 'Grande Closed (Point)', 'Barlow Closed FP (Text)', 'Barlow Closed FP (Point)', 'RDKit 2D', 'RDKit FP', 'ECFP6 2048', 'CDDD', 'ChemBERTa MTR', 'MegaMolBART', 'ChemGPT', 'CLAMP', 'source'])\n",
      "Downloading datasets/solubility_aqsoldb.pkl from terray-public\n",
      "Failed to download solubility_aqsoldb.pkl: Could not connect to the endpoint URL: \"https://terray-public.s3.us-west-2.amazonaws.com/datasets/solubility_aqsoldb.pkl\"\n",
      "Downloading datasets/tox21.pkl from terray-public\n",
      "Failed to download tox21.pkl: Could not connect to the endpoint URL: \"https://terray-public.s3.us-west-2.amazonaws.com/datasets/tox21.pkl\"\n",
      "Downloading datasets/vdss_lombardo.pkl from terray-public\n",
      "File downloaded successfully to ./datasets/vdss_lombardo.pkl\n",
      "vdss_lombardo.pkl:\n",
      " dict_keys(['raw_smiles', 'smiles', 'partition', 'dataset', 'atoms', 'coords', 'target', 'Barlow Venti (Text)', 'Barlow Venti (Point)', 'Grande Open (Text)', 'Grande Open (Point)', 'Tall Closed (Text)', 'Tall Closed (Point)', 'Barlow Closed (Text)', 'Barlow Closed (Point)', 'Grande Closed (Text)', 'Grande Closed (Point)', 'Barlow Closed FP (Text)', 'Barlow Closed FP (Point)', 'RDKit 2D', 'RDKit FP', 'ECFP6 2048', 'CDDD', 'ChemBERTa MTR', 'MegaMolBART', 'ChemGPT', 'CLAMP', 'source'])\n",
      "Downloading datasets/cyp2c9_veith.pkl from terray-public\n",
      "File downloaded successfully to ./datasets/cyp2c9_veith.pkl\n",
      "cyp2c9_veith.pkl:\n",
      " dict_keys(['raw_smiles', 'smiles', 'partition', 'dataset', 'atoms', 'coords', 'target', 'Barlow Venti (Text)', 'Barlow Venti (Point)', 'Grande Open (Text)', 'Grande Open (Point)', 'Tall Closed (Text)', 'Tall Closed (Point)', 'Barlow Closed (Text)', 'Barlow Closed (Point)', 'Grande Closed (Text)', 'Grande Closed (Point)', 'Barlow Closed FP (Text)', 'Barlow Closed FP (Point)', 'RDKit 2D', 'RDKit FP', 'ECFP6 2048', 'CDDD', 'ChemBERTa MTR', 'MegaMolBART', 'ChemGPT', 'CLAMP', 'source'])\n",
      "Downloading datasets/cyp2d6_veith.pkl from terray-public\n",
      "Failed to download cyp2d6_veith.pkl: Max Retries Exceeded\n",
      "Downloading datasets/cyp3a4_veith.pkl from terray-public\n",
      "File downloaded successfully to ./datasets/cyp3a4_veith.pkl\n",
      "cyp3a4_veith.pkl:\n",
      " dict_keys(['raw_smiles', 'smiles', 'partition', 'dataset', 'atoms', 'coords', 'target', 'Barlow Venti (Text)', 'Barlow Venti (Point)', 'Grande Open (Text)', 'Grande Open (Point)', 'Tall Closed (Text)', 'Tall Closed (Point)', 'Barlow Closed (Text)', 'Barlow Closed (Point)', 'Grande Closed (Text)', 'Grande Closed (Point)', 'Barlow Closed FP (Text)', 'Barlow Closed FP (Point)', 'RDKit 2D', 'RDKit FP', 'ECFP6 2048', 'CDDD', 'ChemBERTa MTR', 'MegaMolBART', 'ChemGPT', 'CLAMP', 'source'])\n"
     ]
    }
   ],
   "source": [
    "links_path = 'admet_datasets.txt'\n",
    "dataset_links = load_dataset_links(links_path)\n",
    "local_dir = './datasets'\n",
    "\n",
    "for link in dataset_links:\n",
    "    # extract dataset_name from the link\n",
    "    dataset_name = link.split('/')[-1]\n",
    "    dataset_path = os.path.join(local_dir, dataset_name)\n",
    "\n",
    "    # check if the dataset is already downloaded\n",
    "    if os.path.exists(dataset_path):\n",
    "        print(f\"{dataset_name} already exists\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        download_from_s3(link)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {dataset_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    with open(\"./datasets/delaney.pkl\", \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    print(f'{dataset_name}:\\n {dataset[0].keys()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid SMILES: *C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "def remove_attachment_point(smiles):\n",
    "    return smiles.replace('*', '')\n",
    "\n",
    "# Example Usage\n",
    "clean_smiles = remove_attachment_point('*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC')\n",
    "\n",
    "def substitute_with_hydrogen(smiles):\n",
    "    return smiles.replace('*', 'H')\n",
    "\n",
    "# Example Usage\n",
    "#hydrogenated_smiles = substitute_with_hydrogen('*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC')\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "def validate_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return Chem.MolToSmiles(mol)  # Converts to canonical SMILES and validates\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example Usage\n",
    "validated_smiles = validate_smiles('*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC')\n",
    "if validated_smiles:\n",
    "    print(\"Valid SMILES:\", validated_smiles)\n",
    "else:\n",
    "    print(\"Invalid SMILES after modification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Probing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Assay Index</th>\n",
       "      <th>Analysis Type</th>\n",
       "      <th>Model</th>\n",
       "      <th>AUROC Score</th>\n",
       "      <th>AUROC std</th>\n",
       "      <th>avgp</th>\n",
       "      <th>avgp_std</th>\n",
       "      <th>davgp</th>\n",
       "      <th>davgp_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bace_c_scaffold_split</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>coati_grande</td>\n",
       "      <td>0.798370</td>\n",
       "      <td>0.038282</td>\n",
       "      <td>0.828203</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>0.222940</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bace_c_scaffold_split_0</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>coati_grande</td>\n",
       "      <td>0.837302</td>\n",
       "      <td>0.033348</td>\n",
       "      <td>0.777878</td>\n",
       "      <td>0.048973</td>\n",
       "      <td>0.360659</td>\n",
       "      <td>0.046143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bace_c_scaffold_split_1</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>coati_grande</td>\n",
       "      <td>0.783632</td>\n",
       "      <td>0.038465</td>\n",
       "      <td>0.783008</td>\n",
       "      <td>0.045552</td>\n",
       "      <td>0.266451</td>\n",
       "      <td>0.042737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bace_c_scaffold_split_2</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>coati_grande</td>\n",
       "      <td>0.879080</td>\n",
       "      <td>0.027555</td>\n",
       "      <td>0.860962</td>\n",
       "      <td>0.038691</td>\n",
       "      <td>0.370896</td>\n",
       "      <td>0.046730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bace_c_scaffold_split_3</td>\n",
       "      <td>0</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>coati_grande</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.029263</td>\n",
       "      <td>0.831655</td>\n",
       "      <td>0.045391</td>\n",
       "      <td>0.414436</td>\n",
       "      <td>0.042302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31583</th>\n",
       "      <td>uspto_rclass_scaffold_split_5</td>\n",
       "      <td>9</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>clamp</td>\n",
       "      <td>0.321105</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.072603</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>-0.032576</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31584</th>\n",
       "      <td>uspto_rclass_scaffold_split_6</td>\n",
       "      <td>9</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>clamp</td>\n",
       "      <td>0.311779</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>-0.030980</td>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31585</th>\n",
       "      <td>uspto_rclass_scaffold_split_7</td>\n",
       "      <td>9</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>clamp</td>\n",
       "      <td>0.308478</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>0.068232</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>-0.033948</td>\n",
       "      <td>0.001969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31586</th>\n",
       "      <td>uspto_rclass_scaffold_split_8</td>\n",
       "      <td>9</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>clamp</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.012203</td>\n",
       "      <td>0.070524</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>-0.032255</td>\n",
       "      <td>0.001825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31587</th>\n",
       "      <td>uspto_rclass_scaffold_split_9</td>\n",
       "      <td>9</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>clamp</td>\n",
       "      <td>0.295592</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>0.064859</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>-0.034121</td>\n",
       "      <td>0.001773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31588 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Dataset  Assay Index        Analysis Type  \\\n",
       "0              bace_c_scaffold_split            0  logistic_regression   \n",
       "1            bace_c_scaffold_split_0            0  logistic_regression   \n",
       "2            bace_c_scaffold_split_1            0  logistic_regression   \n",
       "3            bace_c_scaffold_split_2            0  logistic_regression   \n",
       "4            bace_c_scaffold_split_3            0  logistic_regression   \n",
       "...                              ...          ...                  ...   \n",
       "31583  uspto_rclass_scaffold_split_5            9  logistic_regression   \n",
       "31584  uspto_rclass_scaffold_split_6            9  logistic_regression   \n",
       "31585  uspto_rclass_scaffold_split_7            9  logistic_regression   \n",
       "31586  uspto_rclass_scaffold_split_8            9  logistic_regression   \n",
       "31587  uspto_rclass_scaffold_split_9            9  logistic_regression   \n",
       "\n",
       "              Model  AUROC Score  AUROC std      avgp  avgp_std     davgp  \\\n",
       "0      coati_grande     0.798370   0.038282  0.828203  0.045929  0.222940   \n",
       "1      coati_grande     0.837302   0.033348  0.777878  0.048973  0.360659   \n",
       "2      coati_grande     0.783632   0.038465  0.783008  0.045552  0.266451   \n",
       "3      coati_grande     0.879080   0.027555  0.860962  0.038691  0.370896   \n",
       "4      coati_grande     0.871212   0.029263  0.831655  0.045391  0.414436   \n",
       "...             ...          ...        ...       ...       ...       ...   \n",
       "31583         clamp     0.321105   0.013087  0.072603  0.003659 -0.032576   \n",
       "31584         clamp     0.311779   0.012905  0.066600  0.004036 -0.030980   \n",
       "31585         clamp     0.308478   0.012120  0.068232  0.003160 -0.033948   \n",
       "31586         clamp     0.328700   0.012203  0.070524  0.003227 -0.032255   \n",
       "31587         clamp     0.295592   0.011781  0.064859  0.002990 -0.034121   \n",
       "\n",
       "       davgp_std  \n",
       "0       0.044485  \n",
       "1       0.046143  \n",
       "2       0.042737  \n",
       "3       0.046730  \n",
       "4       0.042302  \n",
       "...          ...  \n",
       "31583   0.002343  \n",
       "31584   0.002720  \n",
       "31585   0.001969  \n",
       "31586   0.001825  \n",
       "31587   0.001773  \n",
       "\n",
       "[31588 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv data from /results/linear_probing_results.csv\n",
    "import pandas as pd\n",
    "results = pd.read_csv(\"results/linear_probing_results.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bace_c_scaffold_split', 'bace_c_scaffold_split_0',\n",
       "       'bace_c_scaffold_split_1', 'bace_c_scaffold_split_2',\n",
       "       'bace_c_scaffold_split_3', 'bace_c_scaffold_split_4',\n",
       "       'bace_c_scaffold_split_5', 'bace_c_scaffold_split_6',\n",
       "       'bace_c_scaffold_split_7', 'bace_c_scaffold_split_8',\n",
       "       'bace_c_scaffold_split_9', 'bbbp_scaffold_split',\n",
       "       'bbbp_scaffold_split_0', 'bbbp_scaffold_split_1',\n",
       "       'bbbp_scaffold_split_2', 'bbbp_scaffold_split_3',\n",
       "       'bbbp_scaffold_split_4', 'bbbp_scaffold_split_5',\n",
       "       'bbbp_scaffold_split_6', 'bbbp_scaffold_split_7',\n",
       "       'bbbp_scaffold_split_8', 'bbbp_scaffold_split_9',\n",
       "       'clintox_scaffold_split', 'clintox_scaffold_split_0',\n",
       "       'clintox_scaffold_split_1', 'clintox_scaffold_split_2',\n",
       "       'clintox_scaffold_split_3', 'clintox_scaffold_split_4',\n",
       "       'clintox_scaffold_split_5', 'clintox_scaffold_split_6',\n",
       "       'clintox_scaffold_split_7', 'clintox_scaffold_split_8',\n",
       "       'clintox_scaffold_split_9', 'hiv_scaffold_split',\n",
       "       'hiv_scaffold_split_0', 'hiv_scaffold_split_1',\n",
       "       'hiv_scaffold_split_2', 'hiv_scaffold_split_3',\n",
       "       'hiv_scaffold_split_4', 'hiv_scaffold_split_5',\n",
       "       'hiv_scaffold_split_6', 'hiv_scaffold_split_7',\n",
       "       'hiv_scaffold_split_8', 'hiv_scaffold_split_9',\n",
       "       'sider_scaffold_split', 'sider_scaffold_split_0',\n",
       "       'sider_scaffold_split_1', 'sider_scaffold_split_2',\n",
       "       'sider_scaffold_split_3', 'sider_scaffold_split_4',\n",
       "       'sider_scaffold_split_5', 'sider_scaffold_split_6',\n",
       "       'sider_scaffold_split_7', 'sider_scaffold_split_8',\n",
       "       'sider_scaffold_split_9', 'tox21_scaffold_split',\n",
       "       'tox21_scaffold_split_0', 'tox21_scaffold_split_1',\n",
       "       'tox21_scaffold_split_2', 'tox21_scaffold_split_3',\n",
       "       'tox21_scaffold_split_4', 'tox21_scaffold_split_5',\n",
       "       'tox21_scaffold_split_6', 'tox21_scaffold_split_7',\n",
       "       'tox21_scaffold_split_8', 'tox21_scaffold_split_9',\n",
       "       'tox21_10k_scaffold_split', 'tox21_10k_scaffold_split_0',\n",
       "       'tox21_10k_scaffold_split_1', 'tox21_10k_scaffold_split_2',\n",
       "       'tox21_10k_scaffold_split_3', 'tox21_10k_scaffold_split_4',\n",
       "       'tox21_10k_scaffold_split_5', 'tox21_10k_scaffold_split_6',\n",
       "       'tox21_10k_scaffold_split_7', 'tox21_10k_scaffold_split_8',\n",
       "       'tox21_10k_scaffold_split_9', 'tox21_original_scaffold_split',\n",
       "       'tox21_original_scaffold_split_0',\n",
       "       'tox21_original_scaffold_split_1',\n",
       "       'tox21_original_scaffold_split_2',\n",
       "       'tox21_original_scaffold_split_3',\n",
       "       'tox21_original_scaffold_split_4',\n",
       "       'tox21_original_scaffold_split_5',\n",
       "       'tox21_original_scaffold_split_6',\n",
       "       'tox21_original_scaffold_split_7',\n",
       "       'tox21_original_scaffold_split_8',\n",
       "       'tox21_original_scaffold_split_9', 'toxcast_scaffold_split',\n",
       "       'toxcast_scaffold_split_0', 'toxcast_scaffold_split_1',\n",
       "       'toxcast_scaffold_split_2', 'toxcast_scaffold_split_3',\n",
       "       'toxcast_scaffold_split_4', 'toxcast_scaffold_split_5',\n",
       "       'toxcast_scaffold_split_6', 'toxcast_scaffold_split_7',\n",
       "       'toxcast_scaffold_split_8', 'toxcast_scaffold_split_9',\n",
       "       'uspto_rclass_scaffold_split', 'uspto_rclass_scaffold_split_0',\n",
       "       'uspto_rclass_scaffold_split_1', 'uspto_rclass_scaffold_split_2',\n",
       "       'uspto_rclass_scaffold_split_3', 'uspto_rclass_scaffold_split_4',\n",
       "       'uspto_rclass_scaffold_split_5', 'uspto_rclass_scaffold_split_6',\n",
       "       'uspto_rclass_scaffold_split_7', 'uspto_rclass_scaffold_split_8',\n",
       "       'uspto_rclass_scaffold_split_9'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print unique values in the 'dataset' column\n",
    "results['Dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for bace saved to bace_highlighted.html\n",
      "Results for bbbp saved to bbbp_highlighted.html\n",
      "Results for clintox saved to clintox_highlighted.html\n",
      "Results for hiv saved to hiv_highlighted.html\n",
      "Results for sider saved to sider_highlighted.html\n",
      "Results for tox21 saved to tox21_highlighted.html\n",
      "Results for toxcast saved to toxcast_highlighted.html\n",
      "Results for uspto saved to uspto_highlighted.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_base_name(dataset_name):\n",
    "    return dataset_name.split('_')[0]\n",
    "\n",
    "# Function to apply the highlighting within each group\n",
    "def highlight_max(data):\n",
    "    attr = 'background-color: yellow'\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else '' for v in is_max]\n",
    "    else:  # DataFrame from .apply(axis=None)\n",
    "        is_max = data == data.max().max()\n",
    "        return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                            index=data.index, columns=data.columns)\n",
    "\n",
    "results['Base Dataset'] = results['Dataset'].apply(extract_base_name)\n",
    "\n",
    "# Group by the new 'Base Dataset' and 'Model', and then calculate the mean\n",
    "grouped_df = results.groupby(['Base Dataset', 'Model']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Reset the index if you want 'Base Dataset' and 'Model' back as columns\n",
    "grouped_df.reset_index(inplace=True)\n",
    "# Function to apply the highlighting within each group\n",
    "def highlight_max(data):\n",
    "    attr = 'background-color: yellow'\n",
    "    is_max = data == data.max()\n",
    "    return [attr if v else '' for v in is_max]\n",
    "\n",
    "# Apply the highlight function for each 'Base Dataset' and save results\n",
    "styled_dfs = {}\n",
    "for name, group in grouped_df.groupby('Base Dataset'):\n",
    "    styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std'])\n",
    "    styled_dfs[name] = styled\n",
    "\n",
    "# Optionally save each styled DataFrame to HTML\n",
    "for dataset, styled_df in styled_dfs.items():\n",
    "    styled_df.to_html(f'{dataset}_highlighted.html')\n",
    "    print(f\"Results for {dataset} saved to {dataset}_highlighted.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m         content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# Strip the initial HTML header and body tags to avoid nesting\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<body>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</body>\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     15\u001b[0m         combined_html_content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m content\n\u001b[1;32m     17\u001b[0m combined_html_content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</body></html>\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created HTML files with styles\n",
    "\n",
    "# List of HTML files\n",
    "html_files = [f'{dataset}_highlighted.html' for dataset in styled_dfs.keys()]\n",
    "\n",
    "# Initialize a variable to hold the combined HTML content\n",
    "combined_html_content = '<html><head><style>table {width: 100%; border-collapse: collapse;} th, td {border: 1px solid black; padding: 8px; text-align: left;} th {background-color: #f2f2f2;}</style></head><body>'\n",
    "\n",
    "# Concatenate the content of each styled HTML file\n",
    "for html_file in html_files:\n",
    "    with open(html_file, 'r') as file:\n",
    "        content = file.read()\n",
    "        # Strip the initial HTML header and body tags to avoid nesting\n",
    "        content = content.split('<body>')[1].split('</body>')[0].strip()\n",
    "        combined_html_content += content\n",
    "\n",
    "combined_html_content += '</body></html>'\n",
    "\n",
    "# Save the combined HTML content to a new file\n",
    "with open('combined_highlighted.html', 'w') as file:\n",
    "    file.write(combined_html_content)\n",
    "\n",
    "print(\"Combined HTML with styles saved as 'combined_highlighted.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/sfz06yh5207339s992l9zwc80000gn/T/ipykernel_42555/2940074637.py:31: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n",
      "/var/folders/h5/sfz06yh5207339s992l9zwc80000gn/T/ipykernel_42555/2940074637.py:31: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n",
      "/var/folders/h5/sfz06yh5207339s992l9zwc80000gn/T/ipykernel_42555/2940074637.py:31: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n",
      "/var/folders/h5/sfz06yh5207339s992l9zwc80000gn/T/ipykernel_42555/2940074637.py:31: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n",
      "/var/folders/h5/sfz06yh5207339s992l9zwc80000gn/T/ipykernel_42555/2940074637.py:31: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n",
      "/var/folders/h5/sfz06yh5207339s992l9zwc80000gn/T/ipykernel_42555/2940074637.py:31: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n",
      "/var/folders/h5/sfz06yh5207339s992l9zwc80000gn/T/ipykernel_42555/2940074637.py:31: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n",
      "/var/folders/h5/sfz06yh5207339s992l9zwc80000gn/T/ipykernel_42555/2940074637.py:31: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n",
      "/var/folders/h5/sfz06yh5207339s992l9zwc80000gn/T/ipykernel_42555/2940074637.py:31: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('results/linear_probing_results.csv')\n",
    "\n",
    "# Function to extract the base dataset name\n",
    "def extract_base_name(dataset_name):\n",
    "    if 'tox21_10k' in dataset_name:\n",
    "        return 'tox21_10k'\n",
    "    \n",
    "    return dataset_name.split('_')[0]\n",
    "\n",
    "# Apply the function to the 'Dataset' column\n",
    "df['Base Dataset'] = df['Dataset'].apply(extract_base_name)\n",
    "\n",
    "df.drop(columns=['Assay Index'], inplace=True)\n",
    "\n",
    "# Group by 'Base Dataset' and 'Model', and calculate the mean, ensuring only numeric columns are considered\n",
    "grouped_df = df.groupby(['Base Dataset', 'Model']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Function to apply the highlighting within each group\n",
    "def highlight_max(data):\n",
    "    attr = 'background-color: yellow'\n",
    "    is_max = data == data.max()\n",
    "    return [attr if v else '' for v in is_max]\n",
    "\n",
    "# Combine all HTML contents into one HTML file\n",
    "html_output = '<html><head><style>table {border-collapse: collapse; width: 100%;} th, td {border: 1px solid black; padding: 8px; text-align: left;}</style></head><body>'\n",
    "\n",
    "for name, group in grouped_df.groupby('Base Dataset'):\n",
    "    styled = group.style.apply(highlight_max, subset=['AUROC Score', 'AUROC std', 'avgp', 'avgp_std', 'davgp', 'davgp_std']).render()\n",
    "    html_output += f'<h1>{name}</h1>{styled}'\n",
    "\n",
    "html_output += '</body></html>'\n",
    "\n",
    "# Save the combined HTML to a file\n",
    "with open('combined_results.html', 'w') as file:\n",
    "    file.write(html_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the data from a Parquet file\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3_Semester/Seminar_Practical Work/Code.nosync/COATI/downstream_tasks/data/data/downstream/tox21/compound_names.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DLNN1/lib/python3.10/site-packages/pandas/io/parquet.py:501\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\n\u001b[1;32m    449\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    455\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03m    DataFrame\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m     impl \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    504\u001b[0m         path,\n\u001b[1;32m    505\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    509\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DLNN1/lib/python3.10/site-packages/pandas/io/parquet.py:52\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     50\u001b[0m             error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA suitable version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to import the above resulted in these errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# load parquet file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from a Parquet file\n",
    "df = pd.read_parquet('3_Semester/Seminar_Practical Work/Code.nosync/COATI/downstream_tasks/data/data/downstream/tox21/compound_names.parquet')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coatiEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
